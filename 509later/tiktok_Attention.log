2023-05-09 10:53:25,429 :: INFO :: log info to logs/tiktok_Attention.log
2023-05-09 10:53:25,429 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=512, dataset='tiktok', device='cuda:0', epoch=5, f_epoch=20, f_max=10, feat_dim=64, ite=5, lam=0.1, lr=0.001, model='Attention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=0, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=512, tolog=1, wdi=2)
2023-05-09 11:02:20,820 :: INFO :: log info to logs/tiktok_Attention.log
2023-05-09 11:02:20,820 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=512, dataset='tiktok', device='cuda:0', epoch=5, f_epoch=20, f_max=10, feat_dim=64, ite=5, lam=0.1, lr=0.001, model='Attention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=0, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=512, tolog=1, wdi=2)
2023-05-09 11:03:01,289 :: INFO :: log info to logs/tiktok_Attention.log
2023-05-09 11:03:01,289 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=512, dataset='tiktok', device='cuda:0', epoch=5, f_epoch=20, f_max=10, feat_dim=64, ite=5, lam=0.1, lr=0.001, model='Attention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=0, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=512, tolog=1, wdi=2)
2023-05-09 11:03:02,867 :: INFO :: torch.Size([76083, 384])
2023-05-09 11:04:10,132 :: INFO :: log info to logs/tiktok_Attention.log
2023-05-09 11:04:10,132 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=512, dataset='tiktok', device='cuda:0', epoch=5, f_epoch=20, f_max=10, feat_dim=64, ite=5, lam=0.1, lr=0.001, model='Attention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=0, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=512, tolog=1, wdi=2)
2023-05-09 11:04:11,726 :: INFO :: torch.Size([76083, 384])
2023-05-09 11:07:35,351 :: INFO :: log info to logs/tiktok_Attention.log
2023-05-09 11:07:35,351 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=512, dataset='tiktok', device='cuda:0', epoch=5, f_epoch=20, f_max=10, feat_dim=64, ite=5, lam=0.1, lr=0.001, model='Attention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=0, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=512, tolog=1, wdi=2)
2023-05-09 11:07:36,835 :: INFO :: torch.Size([76083, 384])
2023-05-09 11:15:08,679 :: INFO :: log info to logs/tiktok_Attention.log
2023-05-09 11:15:08,679 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=512, dataset='tiktok', device='cuda:0', epoch=5, f_epoch=20, f_max=10, feat_dim=64, ite=5, lam=0.1, lr=0.001, model='Attention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=0, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=512, tolog=1, wdi=2)
2023-05-09 11:15:10,163 :: INFO :: torch.Size([76083, 384])
2023-05-09 11:16:08,038 :: INFO :: log info to logs/tiktok_Attention.log
2023-05-09 11:16:08,038 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=512, dataset='tiktok', device='cuda:0', epoch=5, f_epoch=20, f_max=10, feat_dim=64, ite=5, lam=0.1, lr=0.001, model='Attention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=0, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=512, tolog=1, wdi=2)
2023-05-09 11:16:09,570 :: INFO :: torch.Size([76083, 384])
2023-05-09 11:17:28,945 :: INFO :: log info to logs/tiktok_Attention.log
2023-05-09 11:17:28,945 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=512, dataset='tiktok', device='cuda:0', epoch=5, f_epoch=20, f_max=10, feat_dim=64, ite=5, lam=0.1, lr=0.001, model='Attention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=0, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=512, tolog=1, wdi=2)
2023-05-09 11:17:30,429 :: INFO :: torch.Size([76083, 384])
2023-05-09 11:18:10,319 :: INFO :: log info to logs/tiktok_Attention.log
2023-05-09 11:18:10,319 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=512, dataset='tiktok', device='cuda:0', epoch=5, f_epoch=20, f_max=10, feat_dim=64, ite=5, lam=0.1, lr=0.001, model='Attention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=0, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=512, tolog=1, wdi=2)
2023-05-09 11:18:11,820 :: INFO :: torch.Size([76083, 384])
2023-05-09 11:31:20,710 :: INFO :: log info to logs/tiktok_Attention.log
2023-05-09 11:31:20,710 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=512, dataset='tiktok', device='cuda:0', epoch=5, f_epoch=20, f_max=10, feat_dim=64, ite=5, lam=0.1, lr=0.001, model='Attention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=0, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=512, tolog=1, wdi=2)
2023-05-09 11:31:22,444 :: INFO :: torch.Size([76083, 384])
2023-05-09 11:41:30,054 :: INFO :: log info to logs/tiktok_Attention.log
2023-05-09 11:41:30,054 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=512, dataset='tiktok', device='cuda:0', epoch=5, f_epoch=20, f_max=10, feat_dim=64, ite=5, lam=0.1, lr=0.001, model='Attention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=0, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=512, tolog=1, wdi=2)
2023-05-09 11:41:31,663 :: INFO :: torch.Size([76083, 384])
2023-05-09 11:42:10,023 :: INFO :: log info to logs/tiktok_Attention.log
2023-05-09 11:42:10,023 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=512, dataset='tiktok', device='cuda:0', epoch=5, f_epoch=20, f_max=10, feat_dim=64, ite=5, lam=0.1, lr=0.001, model='Attention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=0, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=512, tolog=1, wdi=2)
2023-05-09 11:42:11,507 :: INFO :: torch.Size([76083, 384])
2023-05-09 11:44:26,992 :: INFO :: log info to logs/tiktok_Attention.log
2023-05-09 11:44:26,992 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=512, dataset='tiktok', device='cuda:0', epoch=5, f_epoch=20, f_max=10, feat_dim=64, ite=5, lam=0.1, lr=0.001, model='Attention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=0, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=512, tolog=1, wdi=2)
2023-05-09 11:44:28,585 :: INFO :: torch.Size([76083, 384])
2023-05-09 11:46:08,226 :: INFO :: log info to logs/tiktok_Attention.log
2023-05-09 11:46:08,226 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=512, dataset='tiktok', device='cuda:0', epoch=5, f_epoch=20, f_max=10, feat_dim=64, ite=5, lam=0.1, lr=0.001, model='Attention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=0, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=512, tolog=1, wdi=2)
2023-05-09 11:46:09,804 :: INFO :: torch.Size([76083, 384])
2023-05-09 11:49:46,538 :: INFO :: log info to logs/tiktok_Attention.log
2023-05-09 11:49:46,538 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=512, dataset='tiktok', device='cuda:0', epoch=5, f_epoch=20, f_max=10, feat_dim=64, ite=5, lam=0.1, lr=0.001, model='Attention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=0, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=512, tolog=1, wdi=2)
2023-05-09 11:49:48,101 :: INFO :: torch.Size([76083, 384])
2023-05-09 11:50:08,320 :: INFO :: ERM mask: from pre-train tensor([0.5523, 0.5259, 0.5222, 0.5572, 0.5327, 0.5070, 0.5500, 0.5492, 0.5193,
        0.5253, 0.5332, 0.4896, 0.5381, 0.5486, 0.5384, 0.5155, 0.5169, 0.5520,
        0.5182, 0.5483, 0.5210, 0.5311, 0.5536, 0.5246, 0.5053, 0.5231, 0.5224,
        0.5452, 0.5878, 0.5132, 0.5371, 0.5449, 0.5574, 0.5425, 0.4957, 0.4715,
        0.5335, 0.5379, 0.5006, 0.5452, 0.4860, 0.5240, 0.5384, 0.5114, 0.5147,
        0.5179, 0.5337, 0.5109, 0.5339, 0.5208, 0.5157, 0.5156, 0.5030, 0.5171,
        0.5412, 0.5667, 0.5418, 0.5779, 0.5301, 0.5018, 0.5237, 0.5331, 0.5018,
        0.5221, 0.5412, 0.5186, 0.5697, 0.5200, 0.5374, 0.4886, 0.5462, 0.5385,
        0.5334, 0.5632, 0.5535, 0.5001, 0.5610, 0.5176, 0.5444, 0.5573, 0.5491,
        0.5457, 0.5399, 0.5795, 0.4930, 0.5522, 0.5268, 0.5256, 0.5224, 0.4933,
        0.5170, 0.5647, 0.5282, 0.5471, 0.5299, 0.5576, 0.5260, 0.5116, 0.5053,
        0.5105, 0.5310, 0.5316, 0.5313, 0.5211, 0.5433, 0.4741, 0.5302, 0.4994,
        0.5328, 0.5490, 0.5356, 0.5382, 0.5416, 0.5427, 0.4899, 0.4788, 0.5292,
        0.5111, 0.5119, 0.5341, 0.5110, 0.5220, 0.5238, 0.5114, 0.5268, 0.5035,
        0.5178, 0.5598, 0.6188, 0.6112, 0.6297, 0.5914, 0.5822, 0.6098, 0.5972,
        0.5793, 0.5546, 0.5439, 0.5836, 0.5087, 0.6384, 0.5124, 0.6331, 0.6191,
        0.6379, 0.6253, 0.5755, 0.6454, 0.6367, 0.6163, 0.5238, 0.6290, 0.6323,
        0.4405, 0.5312, 0.5224, 0.5356, 0.4422, 0.5724, 0.4324, 0.6181, 0.4321,
        0.6054, 0.5531, 0.5971, 0.5355, 0.4743, 0.5560, 0.5408, 0.6033, 0.6434,
        0.5992, 0.4383, 0.6331, 0.6397, 0.5495, 0.5566, 0.6159, 0.5573, 0.5036,
        0.6179, 0.5539, 0.5696, 0.4443, 0.6122, 0.6447, 0.4550, 0.6233, 0.6560,
        0.4388, 0.4753, 0.5810, 0.6089, 0.4624, 0.5718, 0.6314, 0.6283, 0.5277,
        0.6181, 0.6399, 0.6389, 0.6474, 0.5974, 0.5941, 0.6270, 0.6447, 0.5028,
        0.4349, 0.5705, 0.5839, 0.6426, 0.6031, 0.5620, 0.5096, 0.6088, 0.6536,
        0.6060, 0.4722, 0.6198, 0.4432, 0.6411, 0.5622, 0.6283, 0.6331, 0.5882,
        0.6428, 0.6067, 0.6445, 0.5770, 0.6447, 0.6117, 0.5690, 0.5810, 0.5622,
        0.6089, 0.6416, 0.5664, 0.5543, 0.5334, 0.6065, 0.6115, 0.6256, 0.6344,
        0.6195, 0.5579, 0.6275, 0.4503, 0.6084, 0.5772, 0.5515, 0.5226, 0.6330,
        0.6331, 0.6493, 0.4748, 0.6175, 0.6572, 0.5928, 0.6355, 0.6349, 0.6353,
        0.6695, 0.6037, 0.6250, 0.5876, 0.6446, 0.6170, 0.5594, 0.6146, 0.6268,
        0.5421, 0.6314, 0.5941, 0.5577, 0.6264, 0.5975, 0.6488, 0.6527, 0.5910,
        0.6111, 0.6245, 0.6489, 0.6085, 0.6041, 0.6553, 0.6085, 0.6204, 0.6403,
        0.5950, 0.6281, 0.6303, 0.6395, 0.6359, 0.6108, 0.5381, 0.6115, 0.6221,
        0.5269, 0.6162, 0.6224, 0.5490, 0.6288, 0.6160, 0.5294, 0.6583, 0.5966,
        0.6049, 0.5663, 0.6351, 0.6151, 0.5785, 0.6551, 0.6571, 0.6495, 0.6082,
        0.6212, 0.6220, 0.6025, 0.6219, 0.5652, 0.6332, 0.5718, 0.6434, 0.5699,
        0.6529, 0.5734, 0.6102, 0.6301, 0.5981, 0.6002, 0.6296, 0.5708, 0.6193,
        0.6039, 0.6597, 0.6034, 0.5672, 0.6290, 0.6162, 0.5913, 0.6254, 0.6155,
        0.6071, 0.6643, 0.6338, 0.6073, 0.5505, 0.5813, 0.5580, 0.6123, 0.6094,
        0.5500, 0.6313, 0.5396, 0.6448, 0.5937, 0.5418, 0.6394, 0.5797, 0.6368,
        0.6088, 0.5735, 0.6118, 0.6520, 0.6552, 0.6271, 0.6436, 0.5578, 0.5755,
        0.6347, 0.6170, 0.6345, 0.6267, 0.6242, 0.6599, 0.6558, 0.6137, 0.6050,
        0.6174, 0.5227, 0.6234, 0.6302, 0.6345, 0.6083], dtype=torch.float64)
2023-05-09 12:05:09,648 :: INFO :: log info to logs/tiktok_Attention.log
2023-05-09 12:05:09,648 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=512, dataset='tiktok', device='cuda:0', epoch=5, f_epoch=20, f_max=10, feat_dim=64, ite=5, lam=0.1, lr=0.001, model='Attention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=0, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=512, tolog=1, wdi=2)
2023-05-09 12:05:11,273 :: INFO :: torch.Size([76083, 384])
2023-05-09 12:05:31,867 :: INFO :: ERM mask: from pre-train tensor([0.5523, 0.5259, 0.5222, 0.5572, 0.5327, 0.5070, 0.5500, 0.5492, 0.5193,
        0.5253, 0.5332, 0.4896, 0.5381, 0.5486, 0.5384, 0.5155, 0.5169, 0.5520,
        0.5182, 0.5483, 0.5210, 0.5311, 0.5536, 0.5246, 0.5053, 0.5231, 0.5224,
        0.5452, 0.5878, 0.5132, 0.5371, 0.5449, 0.5574, 0.5425, 0.4957, 0.4715,
        0.5335, 0.5379, 0.5006, 0.5452, 0.4860, 0.5240, 0.5384, 0.5114, 0.5147,
        0.5179, 0.5337, 0.5109, 0.5339, 0.5208, 0.5157, 0.5156, 0.5030, 0.5171,
        0.5412, 0.5667, 0.5418, 0.5779, 0.5301, 0.5018, 0.5237, 0.5331, 0.5018,
        0.5221, 0.5412, 0.5186, 0.5697, 0.5200, 0.5374, 0.4886, 0.5462, 0.5385,
        0.5334, 0.5632, 0.5535, 0.5001, 0.5610, 0.5176, 0.5444, 0.5573, 0.5491,
        0.5457, 0.5399, 0.5795, 0.4930, 0.5522, 0.5268, 0.5256, 0.5224, 0.4933,
        0.5170, 0.5647, 0.5282, 0.5471, 0.5299, 0.5576, 0.5260, 0.5116, 0.5053,
        0.5105, 0.5310, 0.5316, 0.5313, 0.5211, 0.5433, 0.4741, 0.5302, 0.4994,
        0.5328, 0.5490, 0.5356, 0.5382, 0.5416, 0.5427, 0.4899, 0.4788, 0.5292,
        0.5111, 0.5119, 0.5341, 0.5110, 0.5220, 0.5238, 0.5114, 0.5268, 0.5035,
        0.5178, 0.5598, 0.6188, 0.6112, 0.6297, 0.5914, 0.5822, 0.6098, 0.5972,
        0.5793, 0.5546, 0.5439, 0.5836, 0.5087, 0.6384, 0.5124, 0.6331, 0.6191,
        0.6379, 0.6253, 0.5755, 0.6454, 0.6367, 0.6163, 0.5238, 0.6290, 0.6323,
        0.4405, 0.5312, 0.5224, 0.5356, 0.4422, 0.5724, 0.4324, 0.6181, 0.4321,
        0.6054, 0.5531, 0.5971, 0.5355, 0.4743, 0.5560, 0.5408, 0.6033, 0.6434,
        0.5992, 0.4383, 0.6331, 0.6397, 0.5495, 0.5566, 0.6159, 0.5573, 0.5036,
        0.6179, 0.5539, 0.5696, 0.4443, 0.6122, 0.6447, 0.4550, 0.6233, 0.6560,
        0.4388, 0.4753, 0.5810, 0.6089, 0.4624, 0.5718, 0.6314, 0.6283, 0.5277,
        0.6181, 0.6399, 0.6389, 0.6474, 0.5974, 0.5941, 0.6270, 0.6447, 0.5028,
        0.4349, 0.5705, 0.5839, 0.6426, 0.6031, 0.5620, 0.5096, 0.6088, 0.6536,
        0.6060, 0.4722, 0.6198, 0.4432, 0.6411, 0.5622, 0.6283, 0.6331, 0.5882,
        0.6428, 0.6067, 0.6445, 0.5770, 0.6447, 0.6117, 0.5690, 0.5810, 0.5622,
        0.6089, 0.6416, 0.5664, 0.5543, 0.5334, 0.6065, 0.6115, 0.6256, 0.6344,
        0.6195, 0.5579, 0.6275, 0.4503, 0.6084, 0.5772, 0.5515, 0.5226, 0.6330,
        0.6331, 0.6493, 0.4748, 0.6175, 0.6572, 0.5928, 0.6355, 0.6349, 0.6353,
        0.6695, 0.6037, 0.6250, 0.5876, 0.6446, 0.6170, 0.5594, 0.6146, 0.6268,
        0.5421, 0.6314, 0.5941, 0.5577, 0.6264, 0.5975, 0.6488, 0.6527, 0.5910,
        0.6111, 0.6245, 0.6489, 0.6085, 0.6041, 0.6553, 0.6085, 0.6204, 0.6403,
        0.5950, 0.6281, 0.6303, 0.6395, 0.6359, 0.6108, 0.5381, 0.6115, 0.6221,
        0.5269, 0.6162, 0.6224, 0.5490, 0.6288, 0.6160, 0.5294, 0.6583, 0.5966,
        0.6049, 0.5663, 0.6351, 0.6151, 0.5785, 0.6551, 0.6571, 0.6495, 0.6082,
        0.6212, 0.6220, 0.6025, 0.6219, 0.5652, 0.6332, 0.5718, 0.6434, 0.5699,
        0.6529, 0.5734, 0.6102, 0.6301, 0.5981, 0.6002, 0.6296, 0.5708, 0.6193,
        0.6039, 0.6597, 0.6034, 0.5672, 0.6290, 0.6162, 0.5913, 0.6254, 0.6155,
        0.6071, 0.6643, 0.6338, 0.6073, 0.5505, 0.5813, 0.5580, 0.6123, 0.6094,
        0.5500, 0.6313, 0.5396, 0.6448, 0.5937, 0.5418, 0.6394, 0.5797, 0.6368,
        0.6088, 0.5735, 0.6118, 0.6520, 0.6552, 0.6271, 0.6436, 0.5578, 0.5755,
        0.6347, 0.6170, 0.6345, 0.6267, 0.6242, 0.6599, 0.6558, 0.6137, 0.6050,
        0.6174, 0.5227, 0.6234, 0.6302, 0.6345, 0.6083], dtype=torch.float64)
2023-05-09 12:14:47,726 :: INFO :: log info to logs/tiktok_Attention.log
2023-05-09 12:14:47,726 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=512, dataset='tiktok', device='cuda:0', epoch=5, f_epoch=20, f_max=10, feat_dim=64, ite=5, lam=0.1, lr=0.001, model='Attention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=0, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=512, tolog=1, wdi=2)
2023-05-09 12:14:49,288 :: INFO :: torch.Size([76083, 384])
2023-05-09 12:15:10,054 :: INFO :: ERM mask: from pre-train tensor([0.5523, 0.5259, 0.5222, 0.5572, 0.5327, 0.5070, 0.5500, 0.5492, 0.5193,
        0.5253, 0.5332, 0.4896, 0.5381, 0.5486, 0.5384, 0.5155, 0.5169, 0.5520,
        0.5182, 0.5483, 0.5210, 0.5311, 0.5536, 0.5246, 0.5053, 0.5231, 0.5224,
        0.5452, 0.5878, 0.5132, 0.5371, 0.5449, 0.5574, 0.5425, 0.4957, 0.4715,
        0.5335, 0.5379, 0.5006, 0.5452, 0.4860, 0.5240, 0.5384, 0.5114, 0.5147,
        0.5179, 0.5337, 0.5109, 0.5339, 0.5208, 0.5157, 0.5156, 0.5030, 0.5171,
        0.5412, 0.5667, 0.5418, 0.5779, 0.5301, 0.5018, 0.5237, 0.5331, 0.5018,
        0.5221, 0.5412, 0.5186, 0.5697, 0.5200, 0.5374, 0.4886, 0.5462, 0.5385,
        0.5334, 0.5632, 0.5535, 0.5001, 0.5610, 0.5176, 0.5444, 0.5573, 0.5491,
        0.5457, 0.5399, 0.5795, 0.4930, 0.5522, 0.5268, 0.5256, 0.5224, 0.4933,
        0.5170, 0.5647, 0.5282, 0.5471, 0.5299, 0.5576, 0.5260, 0.5116, 0.5053,
        0.5105, 0.5310, 0.5316, 0.5313, 0.5211, 0.5433, 0.4741, 0.5302, 0.4994,
        0.5328, 0.5490, 0.5356, 0.5382, 0.5416, 0.5427, 0.4899, 0.4788, 0.5292,
        0.5111, 0.5119, 0.5341, 0.5110, 0.5220, 0.5238, 0.5114, 0.5268, 0.5035,
        0.5178, 0.5598, 0.6188, 0.6112, 0.6297, 0.5914, 0.5822, 0.6098, 0.5972,
        0.5793, 0.5546, 0.5439, 0.5836, 0.5087, 0.6384, 0.5124, 0.6331, 0.6191,
        0.6379, 0.6253, 0.5755, 0.6454, 0.6367, 0.6163, 0.5238, 0.6290, 0.6323,
        0.4405, 0.5312, 0.5224, 0.5356, 0.4422, 0.5724, 0.4324, 0.6181, 0.4321,
        0.6054, 0.5531, 0.5971, 0.5355, 0.4743, 0.5560, 0.5408, 0.6033, 0.6434,
        0.5992, 0.4383, 0.6331, 0.6397, 0.5495, 0.5566, 0.6159, 0.5573, 0.5036,
        0.6179, 0.5539, 0.5696, 0.4443, 0.6122, 0.6447, 0.4550, 0.6233, 0.6560,
        0.4388, 0.4753, 0.5810, 0.6089, 0.4624, 0.5718, 0.6314, 0.6283, 0.5277,
        0.6181, 0.6399, 0.6389, 0.6474, 0.5974, 0.5941, 0.6270, 0.6447, 0.5028,
        0.4349, 0.5705, 0.5839, 0.6426, 0.6031, 0.5620, 0.5096, 0.6088, 0.6536,
        0.6060, 0.4722, 0.6198, 0.4432, 0.6411, 0.5622, 0.6283, 0.6331, 0.5882,
        0.6428, 0.6067, 0.6445, 0.5770, 0.6447, 0.6117, 0.5690, 0.5810, 0.5622,
        0.6089, 0.6416, 0.5664, 0.5543, 0.5334, 0.6065, 0.6115, 0.6256, 0.6344,
        0.6195, 0.5579, 0.6275, 0.4503, 0.6084, 0.5772, 0.5515, 0.5226, 0.6330,
        0.6331, 0.6493, 0.4748, 0.6175, 0.6572, 0.5928, 0.6355, 0.6349, 0.6353,
        0.6695, 0.6037, 0.6250, 0.5876, 0.6446, 0.6170, 0.5594, 0.6146, 0.6268,
        0.5421, 0.6314, 0.5941, 0.5577, 0.6264, 0.5975, 0.6488, 0.6527, 0.5910,
        0.6111, 0.6245, 0.6489, 0.6085, 0.6041, 0.6553, 0.6085, 0.6204, 0.6403,
        0.5950, 0.6281, 0.6303, 0.6395, 0.6359, 0.6108, 0.5381, 0.6115, 0.6221,
        0.5269, 0.6162, 0.6224, 0.5490, 0.6288, 0.6160, 0.5294, 0.6583, 0.5966,
        0.6049, 0.5663, 0.6351, 0.6151, 0.5785, 0.6551, 0.6571, 0.6495, 0.6082,
        0.6212, 0.6220, 0.6025, 0.6219, 0.5652, 0.6332, 0.5718, 0.6434, 0.5699,
        0.6529, 0.5734, 0.6102, 0.6301, 0.5981, 0.6002, 0.6296, 0.5708, 0.6193,
        0.6039, 0.6597, 0.6034, 0.5672, 0.6290, 0.6162, 0.5913, 0.6254, 0.6155,
        0.6071, 0.6643, 0.6338, 0.6073, 0.5505, 0.5813, 0.5580, 0.6123, 0.6094,
        0.5500, 0.6313, 0.5396, 0.6448, 0.5937, 0.5418, 0.6394, 0.5797, 0.6368,
        0.6088, 0.5735, 0.6118, 0.6520, 0.6552, 0.6271, 0.6436, 0.5578, 0.5755,
        0.6347, 0.6170, 0.6345, 0.6267, 0.6242, 0.6599, 0.6558, 0.6137, 0.6050,
        0.6174, 0.5227, 0.6234, 0.6302, 0.6345, 0.6083], dtype=torch.float64)
2023-05-09 12:17:04,726 :: INFO :: log info to logs/tiktok_Attention.log
2023-05-09 12:17:04,726 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=512, dataset='tiktok', device='cuda:0', epoch=5, f_epoch=20, f_max=10, feat_dim=64, ite=5, lam=0.1, lr=0.001, model='Attention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=0, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=512, tolog=1, wdi=2)
2023-05-09 12:17:06,273 :: INFO :: torch.Size([76083, 384])
2023-05-09 12:17:26,617 :: INFO :: ERM mask: from pre-train tensor([0.5523, 0.5259, 0.5222, 0.5572, 0.5327, 0.5070, 0.5500, 0.5492, 0.5193,
        0.5253, 0.5332, 0.4896, 0.5381, 0.5486, 0.5384, 0.5155, 0.5169, 0.5520,
        0.5182, 0.5483, 0.5210, 0.5311, 0.5536, 0.5246, 0.5053, 0.5231, 0.5224,
        0.5452, 0.5878, 0.5132, 0.5371, 0.5449, 0.5574, 0.5425, 0.4957, 0.4715,
        0.5335, 0.5379, 0.5006, 0.5452, 0.4860, 0.5240, 0.5384, 0.5114, 0.5147,
        0.5179, 0.5337, 0.5109, 0.5339, 0.5208, 0.5157, 0.5156, 0.5030, 0.5171,
        0.5412, 0.5667, 0.5418, 0.5779, 0.5301, 0.5018, 0.5237, 0.5331, 0.5018,
        0.5221, 0.5412, 0.5186, 0.5697, 0.5200, 0.5374, 0.4886, 0.5462, 0.5385,
        0.5334, 0.5632, 0.5535, 0.5001, 0.5610, 0.5176, 0.5444, 0.5573, 0.5491,
        0.5457, 0.5399, 0.5795, 0.4930, 0.5522, 0.5268, 0.5256, 0.5224, 0.4933,
        0.5170, 0.5647, 0.5282, 0.5471, 0.5299, 0.5576, 0.5260, 0.5116, 0.5053,
        0.5105, 0.5310, 0.5316, 0.5313, 0.5211, 0.5433, 0.4741, 0.5302, 0.4994,
        0.5328, 0.5490, 0.5356, 0.5382, 0.5416, 0.5427, 0.4899, 0.4788, 0.5292,
        0.5111, 0.5119, 0.5341, 0.5110, 0.5220, 0.5238, 0.5114, 0.5268, 0.5035,
        0.5178, 0.5598, 0.6188, 0.6112, 0.6297, 0.5914, 0.5822, 0.6098, 0.5972,
        0.5793, 0.5546, 0.5439, 0.5836, 0.5087, 0.6384, 0.5124, 0.6331, 0.6191,
        0.6379, 0.6253, 0.5755, 0.6454, 0.6367, 0.6163, 0.5238, 0.6290, 0.6323,
        0.4405, 0.5312, 0.5224, 0.5356, 0.4422, 0.5724, 0.4324, 0.6181, 0.4321,
        0.6054, 0.5531, 0.5971, 0.5355, 0.4743, 0.5560, 0.5408, 0.6033, 0.6434,
        0.5992, 0.4383, 0.6331, 0.6397, 0.5495, 0.5566, 0.6159, 0.5573, 0.5036,
        0.6179, 0.5539, 0.5696, 0.4443, 0.6122, 0.6447, 0.4550, 0.6233, 0.6560,
        0.4388, 0.4753, 0.5810, 0.6089, 0.4624, 0.5718, 0.6314, 0.6283, 0.5277,
        0.6181, 0.6399, 0.6389, 0.6474, 0.5974, 0.5941, 0.6270, 0.6447, 0.5028,
        0.4349, 0.5705, 0.5839, 0.6426, 0.6031, 0.5620, 0.5096, 0.6088, 0.6536,
        0.6060, 0.4722, 0.6198, 0.4432, 0.6411, 0.5622, 0.6283, 0.6331, 0.5882,
        0.6428, 0.6067, 0.6445, 0.5770, 0.6447, 0.6117, 0.5690, 0.5810, 0.5622,
        0.6089, 0.6416, 0.5664, 0.5543, 0.5334, 0.6065, 0.6115, 0.6256, 0.6344,
        0.6195, 0.5579, 0.6275, 0.4503, 0.6084, 0.5772, 0.5515, 0.5226, 0.6330,
        0.6331, 0.6493, 0.4748, 0.6175, 0.6572, 0.5928, 0.6355, 0.6349, 0.6353,
        0.6695, 0.6037, 0.6250, 0.5876, 0.6446, 0.6170, 0.5594, 0.6146, 0.6268,
        0.5421, 0.6314, 0.5941, 0.5577, 0.6264, 0.5975, 0.6488, 0.6527, 0.5910,
        0.6111, 0.6245, 0.6489, 0.6085, 0.6041, 0.6553, 0.6085, 0.6204, 0.6403,
        0.5950, 0.6281, 0.6303, 0.6395, 0.6359, 0.6108, 0.5381, 0.6115, 0.6221,
        0.5269, 0.6162, 0.6224, 0.5490, 0.6288, 0.6160, 0.5294, 0.6583, 0.5966,
        0.6049, 0.5663, 0.6351, 0.6151, 0.5785, 0.6551, 0.6571, 0.6495, 0.6082,
        0.6212, 0.6220, 0.6025, 0.6219, 0.5652, 0.6332, 0.5718, 0.6434, 0.5699,
        0.6529, 0.5734, 0.6102, 0.6301, 0.5981, 0.6002, 0.6296, 0.5708, 0.6193,
        0.6039, 0.6597, 0.6034, 0.5672, 0.6290, 0.6162, 0.5913, 0.6254, 0.6155,
        0.6071, 0.6643, 0.6338, 0.6073, 0.5505, 0.5813, 0.5580, 0.6123, 0.6094,
        0.5500, 0.6313, 0.5396, 0.6448, 0.5937, 0.5418, 0.6394, 0.5797, 0.6368,
        0.6088, 0.5735, 0.6118, 0.6520, 0.6552, 0.6271, 0.6436, 0.5578, 0.5755,
        0.6347, 0.6170, 0.6345, 0.6267, 0.6242, 0.6599, 0.6558, 0.6137, 0.6050,
        0.6174, 0.5227, 0.6234, 0.6302, 0.6345, 0.6083], dtype=torch.float64)
2023-05-09 12:30:39,867 :: INFO :: log info to logs/tiktok_Attention.log
2023-05-09 12:30:39,867 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=512, dataset='tiktok', device='cuda:0', epoch=5, f_epoch=20, f_max=10, feat_dim=64, ite=5, lam=0.1, lr=0.001, model='Attention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=0, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=512, tolog=1, wdi=2)
2023-05-09 12:30:41,507 :: INFO :: torch.Size([76083, 384])
2023-05-09 12:31:01,804 :: INFO :: ERM mask: from pre-train tensor([0.5523, 0.5259, 0.5222, 0.5572, 0.5327, 0.5070, 0.5500, 0.5492, 0.5193,
        0.5253, 0.5332, 0.4896, 0.5381, 0.5486, 0.5384, 0.5155, 0.5169, 0.5520,
        0.5182, 0.5483, 0.5210, 0.5311, 0.5536, 0.5246, 0.5053, 0.5231, 0.5224,
        0.5452, 0.5878, 0.5132, 0.5371, 0.5449, 0.5574, 0.5425, 0.4957, 0.4715,
        0.5335, 0.5379, 0.5006, 0.5452, 0.4860, 0.5240, 0.5384, 0.5114, 0.5147,
        0.5179, 0.5337, 0.5109, 0.5339, 0.5208, 0.5157, 0.5156, 0.5030, 0.5171,
        0.5412, 0.5667, 0.5418, 0.5779, 0.5301, 0.5018, 0.5237, 0.5331, 0.5018,
        0.5221, 0.5412, 0.5186, 0.5697, 0.5200, 0.5374, 0.4886, 0.5462, 0.5385,
        0.5334, 0.5632, 0.5535, 0.5001, 0.5610, 0.5176, 0.5444, 0.5573, 0.5491,
        0.5457, 0.5399, 0.5795, 0.4930, 0.5522, 0.5268, 0.5256, 0.5224, 0.4933,
        0.5170, 0.5647, 0.5282, 0.5471, 0.5299, 0.5576, 0.5260, 0.5116, 0.5053,
        0.5105, 0.5310, 0.5316, 0.5313, 0.5211, 0.5433, 0.4741, 0.5302, 0.4994,
        0.5328, 0.5490, 0.5356, 0.5382, 0.5416, 0.5427, 0.4899, 0.4788, 0.5292,
        0.5111, 0.5119, 0.5341, 0.5110, 0.5220, 0.5238, 0.5114, 0.5268, 0.5035,
        0.5178, 0.5598, 0.6188, 0.6112, 0.6297, 0.5914, 0.5822, 0.6098, 0.5972,
        0.5793, 0.5546, 0.5439, 0.5836, 0.5087, 0.6384, 0.5124, 0.6331, 0.6191,
        0.6379, 0.6253, 0.5755, 0.6454, 0.6367, 0.6163, 0.5238, 0.6290, 0.6323,
        0.4405, 0.5312, 0.5224, 0.5356, 0.4422, 0.5724, 0.4324, 0.6181, 0.4321,
        0.6054, 0.5531, 0.5971, 0.5355, 0.4743, 0.5560, 0.5408, 0.6033, 0.6434,
        0.5992, 0.4383, 0.6331, 0.6397, 0.5495, 0.5566, 0.6159, 0.5573, 0.5036,
        0.6179, 0.5539, 0.5696, 0.4443, 0.6122, 0.6447, 0.4550, 0.6233, 0.6560,
        0.4388, 0.4753, 0.5810, 0.6089, 0.4624, 0.5718, 0.6314, 0.6283, 0.5277,
        0.6181, 0.6399, 0.6389, 0.6474, 0.5974, 0.5941, 0.6270, 0.6447, 0.5028,
        0.4349, 0.5705, 0.5839, 0.6426, 0.6031, 0.5620, 0.5096, 0.6088, 0.6536,
        0.6060, 0.4722, 0.6198, 0.4432, 0.6411, 0.5622, 0.6283, 0.6331, 0.5882,
        0.6428, 0.6067, 0.6445, 0.5770, 0.6447, 0.6117, 0.5690, 0.5810, 0.5622,
        0.6089, 0.6416, 0.5664, 0.5543, 0.5334, 0.6065, 0.6115, 0.6256, 0.6344,
        0.6195, 0.5579, 0.6275, 0.4503, 0.6084, 0.5772, 0.5515, 0.5226, 0.6330,
        0.6331, 0.6493, 0.4748, 0.6175, 0.6572, 0.5928, 0.6355, 0.6349, 0.6353,
        0.6695, 0.6037, 0.6250, 0.5876, 0.6446, 0.6170, 0.5594, 0.6146, 0.6268,
        0.5421, 0.6314, 0.5941, 0.5577, 0.6264, 0.5975, 0.6488, 0.6527, 0.5910,
        0.6111, 0.6245, 0.6489, 0.6085, 0.6041, 0.6553, 0.6085, 0.6204, 0.6403,
        0.5950, 0.6281, 0.6303, 0.6395, 0.6359, 0.6108, 0.5381, 0.6115, 0.6221,
        0.5269, 0.6162, 0.6224, 0.5490, 0.6288, 0.6160, 0.5294, 0.6583, 0.5966,
        0.6049, 0.5663, 0.6351, 0.6151, 0.5785, 0.6551, 0.6571, 0.6495, 0.6082,
        0.6212, 0.6220, 0.6025, 0.6219, 0.5652, 0.6332, 0.5718, 0.6434, 0.5699,
        0.6529, 0.5734, 0.6102, 0.6301, 0.5981, 0.6002, 0.6296, 0.5708, 0.6193,
        0.6039, 0.6597, 0.6034, 0.5672, 0.6290, 0.6162, 0.5913, 0.6254, 0.6155,
        0.6071, 0.6643, 0.6338, 0.6073, 0.5505, 0.5813, 0.5580, 0.6123, 0.6094,
        0.5500, 0.6313, 0.5396, 0.6448, 0.5937, 0.5418, 0.6394, 0.5797, 0.6368,
        0.6088, 0.5735, 0.6118, 0.6520, 0.6552, 0.6271, 0.6436, 0.5578, 0.5755,
        0.6347, 0.6170, 0.6345, 0.6267, 0.6242, 0.6599, 0.6558, 0.6137, 0.6050,
        0.6174, 0.5227, 0.6234, 0.6302, 0.6345, 0.6083], dtype=torch.float64)
2023-05-09 12:31:21,913 :: INFO :: Epoch 5: loss tensor(0.9275, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.3382109999656677, V.norm 0.34504234790802, MLP.norm 0.024449408054351807
2023-05-09 12:31:44,288 :: INFO :: log info to logs/tiktok_Attention.log
2023-05-09 12:31:44,288 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=256, dataset='tiktok', device='cuda:0', epoch=5, f_epoch=20, f_max=10, feat_dim=64, ite=5, lam=0.1, lr=0.001, model='Attention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=0, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=256, tolog=1, wdi=2)
2023-05-09 12:31:45,819 :: INFO :: torch.Size([76083, 384])
2023-05-09 12:32:05,429 :: INFO :: ERM mask: from pre-train tensor([0.5523, 0.5259, 0.5222, 0.5572, 0.5327, 0.5070, 0.5500, 0.5492, 0.5193,
        0.5253, 0.5332, 0.4896, 0.5381, 0.5486, 0.5384, 0.5155, 0.5169, 0.5520,
        0.5182, 0.5483, 0.5210, 0.5311, 0.5536, 0.5246, 0.5053, 0.5231, 0.5224,
        0.5452, 0.5878, 0.5132, 0.5371, 0.5449, 0.5574, 0.5425, 0.4957, 0.4715,
        0.5335, 0.5379, 0.5006, 0.5452, 0.4860, 0.5240, 0.5384, 0.5114, 0.5147,
        0.5179, 0.5337, 0.5109, 0.5339, 0.5208, 0.5157, 0.5156, 0.5030, 0.5171,
        0.5412, 0.5667, 0.5418, 0.5779, 0.5301, 0.5018, 0.5237, 0.5331, 0.5018,
        0.5221, 0.5412, 0.5186, 0.5697, 0.5200, 0.5374, 0.4886, 0.5462, 0.5385,
        0.5334, 0.5632, 0.5535, 0.5001, 0.5610, 0.5176, 0.5444, 0.5573, 0.5491,
        0.5457, 0.5399, 0.5795, 0.4930, 0.5522, 0.5268, 0.5256, 0.5224, 0.4933,
        0.5170, 0.5647, 0.5282, 0.5471, 0.5299, 0.5576, 0.5260, 0.5116, 0.5053,
        0.5105, 0.5310, 0.5316, 0.5313, 0.5211, 0.5433, 0.4741, 0.5302, 0.4994,
        0.5328, 0.5490, 0.5356, 0.5382, 0.5416, 0.5427, 0.4899, 0.4788, 0.5292,
        0.5111, 0.5119, 0.5341, 0.5110, 0.5220, 0.5238, 0.5114, 0.5268, 0.5035,
        0.5178, 0.5598, 0.6188, 0.6112, 0.6297, 0.5914, 0.5822, 0.6098, 0.5972,
        0.5793, 0.5546, 0.5439, 0.5836, 0.5087, 0.6384, 0.5124, 0.6331, 0.6191,
        0.6379, 0.6253, 0.5755, 0.6454, 0.6367, 0.6163, 0.5238, 0.6290, 0.6323,
        0.4405, 0.5312, 0.5224, 0.5356, 0.4422, 0.5724, 0.4324, 0.6181, 0.4321,
        0.6054, 0.5531, 0.5971, 0.5355, 0.4743, 0.5560, 0.5408, 0.6033, 0.6434,
        0.5992, 0.4383, 0.6331, 0.6397, 0.5495, 0.5566, 0.6159, 0.5573, 0.5036,
        0.6179, 0.5539, 0.5696, 0.4443, 0.6122, 0.6447, 0.4550, 0.6233, 0.6560,
        0.4388, 0.4753, 0.5810, 0.6089, 0.4624, 0.5718, 0.6314, 0.6283, 0.5277,
        0.6181, 0.6399, 0.6389, 0.6474, 0.5974, 0.5941, 0.6270, 0.6447, 0.5028,
        0.4349, 0.5705, 0.5839, 0.6426, 0.6031, 0.5620, 0.5096, 0.6088, 0.6536,
        0.6060, 0.4722, 0.6198, 0.4432, 0.6411, 0.5622, 0.6283, 0.6331, 0.5882,
        0.6428, 0.6067, 0.6445, 0.5770, 0.6447, 0.6117, 0.5690, 0.5810, 0.5622,
        0.6089, 0.6416, 0.5664, 0.5543, 0.5334, 0.6065, 0.6115, 0.6256, 0.6344,
        0.6195, 0.5579, 0.6275, 0.4503, 0.6084, 0.5772, 0.5515, 0.5226, 0.6330,
        0.6331, 0.6493, 0.4748, 0.6175, 0.6572, 0.5928, 0.6355, 0.6349, 0.6353,
        0.6695, 0.6037, 0.6250, 0.5876, 0.6446, 0.6170, 0.5594, 0.6146, 0.6268,
        0.5421, 0.6314, 0.5941, 0.5577, 0.6264, 0.5975, 0.6488, 0.6527, 0.5910,
        0.6111, 0.6245, 0.6489, 0.6085, 0.6041, 0.6553, 0.6085, 0.6204, 0.6403,
        0.5950, 0.6281, 0.6303, 0.6395, 0.6359, 0.6108, 0.5381, 0.6115, 0.6221,
        0.5269, 0.6162, 0.6224, 0.5490, 0.6288, 0.6160, 0.5294, 0.6583, 0.5966,
        0.6049, 0.5663, 0.6351, 0.6151, 0.5785, 0.6551, 0.6571, 0.6495, 0.6082,
        0.6212, 0.6220, 0.6025, 0.6219, 0.5652, 0.6332, 0.5718, 0.6434, 0.5699,
        0.6529, 0.5734, 0.6102, 0.6301, 0.5981, 0.6002, 0.6296, 0.5708, 0.6193,
        0.6039, 0.6597, 0.6034, 0.5672, 0.6290, 0.6162, 0.5913, 0.6254, 0.6155,
        0.6071, 0.6643, 0.6338, 0.6073, 0.5505, 0.5813, 0.5580, 0.6123, 0.6094,
        0.5500, 0.6313, 0.5396, 0.6448, 0.5937, 0.5418, 0.6394, 0.5797, 0.6368,
        0.6088, 0.5735, 0.6118, 0.6520, 0.6552, 0.6271, 0.6436, 0.5578, 0.5755,
        0.6347, 0.6170, 0.6345, 0.6267, 0.6242, 0.6599, 0.6558, 0.6137, 0.6050,
        0.6174, 0.5227, 0.6234, 0.6302, 0.6345, 0.6083], dtype=torch.float64)
2023-05-09 12:32:23,804 :: INFO :: Epoch 5: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.011279151774942875, V.norm 0.011505632661283016, MLP.norm 0.0008211754029616714
2023-05-09 12:32:44,882 :: INFO :: log info to logs/tiktok_Attention.log
2023-05-09 12:32:44,882 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=128, dataset='tiktok', device='cuda:0', epoch=5, f_epoch=20, f_max=10, feat_dim=64, ite=5, lam=0.1, lr=0.001, model='Attention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=0, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=128, tolog=1, wdi=2)
2023-05-09 12:32:46,445 :: INFO :: torch.Size([76083, 384])
2023-05-09 12:33:06,913 :: INFO :: ERM mask: from pre-train tensor([0.5523, 0.5259, 0.5222, 0.5572, 0.5327, 0.5070, 0.5500, 0.5492, 0.5193,
        0.5253, 0.5332, 0.4896, 0.5381, 0.5486, 0.5384, 0.5155, 0.5169, 0.5520,
        0.5182, 0.5483, 0.5210, 0.5311, 0.5536, 0.5246, 0.5053, 0.5231, 0.5224,
        0.5452, 0.5878, 0.5132, 0.5371, 0.5449, 0.5574, 0.5425, 0.4957, 0.4715,
        0.5335, 0.5379, 0.5006, 0.5452, 0.4860, 0.5240, 0.5384, 0.5114, 0.5147,
        0.5179, 0.5337, 0.5109, 0.5339, 0.5208, 0.5157, 0.5156, 0.5030, 0.5171,
        0.5412, 0.5667, 0.5418, 0.5779, 0.5301, 0.5018, 0.5237, 0.5331, 0.5018,
        0.5221, 0.5412, 0.5186, 0.5697, 0.5200, 0.5374, 0.4886, 0.5462, 0.5385,
        0.5334, 0.5632, 0.5535, 0.5001, 0.5610, 0.5176, 0.5444, 0.5573, 0.5491,
        0.5457, 0.5399, 0.5795, 0.4930, 0.5522, 0.5268, 0.5256, 0.5224, 0.4933,
        0.5170, 0.5647, 0.5282, 0.5471, 0.5299, 0.5576, 0.5260, 0.5116, 0.5053,
        0.5105, 0.5310, 0.5316, 0.5313, 0.5211, 0.5433, 0.4741, 0.5302, 0.4994,
        0.5328, 0.5490, 0.5356, 0.5382, 0.5416, 0.5427, 0.4899, 0.4788, 0.5292,
        0.5111, 0.5119, 0.5341, 0.5110, 0.5220, 0.5238, 0.5114, 0.5268, 0.5035,
        0.5178, 0.5598, 0.6188, 0.6112, 0.6297, 0.5914, 0.5822, 0.6098, 0.5972,
        0.5793, 0.5546, 0.5439, 0.5836, 0.5087, 0.6384, 0.5124, 0.6331, 0.6191,
        0.6379, 0.6253, 0.5755, 0.6454, 0.6367, 0.6163, 0.5238, 0.6290, 0.6323,
        0.4405, 0.5312, 0.5224, 0.5356, 0.4422, 0.5724, 0.4324, 0.6181, 0.4321,
        0.6054, 0.5531, 0.5971, 0.5355, 0.4743, 0.5560, 0.5408, 0.6033, 0.6434,
        0.5992, 0.4383, 0.6331, 0.6397, 0.5495, 0.5566, 0.6159, 0.5573, 0.5036,
        0.6179, 0.5539, 0.5696, 0.4443, 0.6122, 0.6447, 0.4550, 0.6233, 0.6560,
        0.4388, 0.4753, 0.5810, 0.6089, 0.4624, 0.5718, 0.6314, 0.6283, 0.5277,
        0.6181, 0.6399, 0.6389, 0.6474, 0.5974, 0.5941, 0.6270, 0.6447, 0.5028,
        0.4349, 0.5705, 0.5839, 0.6426, 0.6031, 0.5620, 0.5096, 0.6088, 0.6536,
        0.6060, 0.4722, 0.6198, 0.4432, 0.6411, 0.5622, 0.6283, 0.6331, 0.5882,
        0.6428, 0.6067, 0.6445, 0.5770, 0.6447, 0.6117, 0.5690, 0.5810, 0.5622,
        0.6089, 0.6416, 0.5664, 0.5543, 0.5334, 0.6065, 0.6115, 0.6256, 0.6344,
        0.6195, 0.5579, 0.6275, 0.4503, 0.6084, 0.5772, 0.5515, 0.5226, 0.6330,
        0.6331, 0.6493, 0.4748, 0.6175, 0.6572, 0.5928, 0.6355, 0.6349, 0.6353,
        0.6695, 0.6037, 0.6250, 0.5876, 0.6446, 0.6170, 0.5594, 0.6146, 0.6268,
        0.5421, 0.6314, 0.5941, 0.5577, 0.6264, 0.5975, 0.6488, 0.6527, 0.5910,
        0.6111, 0.6245, 0.6489, 0.6085, 0.6041, 0.6553, 0.6085, 0.6204, 0.6403,
        0.5950, 0.6281, 0.6303, 0.6395, 0.6359, 0.6108, 0.5381, 0.6115, 0.6221,
        0.5269, 0.6162, 0.6224, 0.5490, 0.6288, 0.6160, 0.5294, 0.6583, 0.5966,
        0.6049, 0.5663, 0.6351, 0.6151, 0.5785, 0.6551, 0.6571, 0.6495, 0.6082,
        0.6212, 0.6220, 0.6025, 0.6219, 0.5652, 0.6332, 0.5718, 0.6434, 0.5699,
        0.6529, 0.5734, 0.6102, 0.6301, 0.5981, 0.6002, 0.6296, 0.5708, 0.6193,
        0.6039, 0.6597, 0.6034, 0.5672, 0.6290, 0.6162, 0.5913, 0.6254, 0.6155,
        0.6071, 0.6643, 0.6338, 0.6073, 0.5505, 0.5813, 0.5580, 0.6123, 0.6094,
        0.5500, 0.6313, 0.5396, 0.6448, 0.5937, 0.5418, 0.6394, 0.5797, 0.6368,
        0.6088, 0.5735, 0.6118, 0.6520, 0.6552, 0.6271, 0.6436, 0.5578, 0.5755,
        0.6347, 0.6170, 0.6345, 0.6267, 0.6242, 0.6599, 0.6558, 0.6137, 0.6050,
        0.6174, 0.5227, 0.6234, 0.6302, 0.6345, 0.6083], dtype=torch.float64)
2023-05-09 12:35:14,538 :: INFO :: log info to logs/tiktok_Attention.log
2023-05-09 12:35:14,538 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=256, dataset='tiktok', device='cuda:0', epoch=5, f_epoch=20, f_max=10, feat_dim=32, ite=5, lam=0.1, lr=0.001, model='Attention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=0, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=256, tolog=1, wdi=2)
2023-05-09 12:35:16,148 :: INFO :: torch.Size([76083, 384])
2023-05-09 12:35:36,069 :: INFO :: ERM mask: from pre-train tensor([0.5523, 0.5259, 0.5222, 0.5572, 0.5327, 0.5070, 0.5500, 0.5492, 0.5193,
        0.5253, 0.5332, 0.4896, 0.5381, 0.5486, 0.5384, 0.5155, 0.5169, 0.5520,
        0.5182, 0.5483, 0.5210, 0.5311, 0.5536, 0.5246, 0.5053, 0.5231, 0.5224,
        0.5452, 0.5878, 0.5132, 0.5371, 0.5449, 0.5574, 0.5425, 0.4957, 0.4715,
        0.5335, 0.5379, 0.5006, 0.5452, 0.4860, 0.5240, 0.5384, 0.5114, 0.5147,
        0.5179, 0.5337, 0.5109, 0.5339, 0.5208, 0.5157, 0.5156, 0.5030, 0.5171,
        0.5412, 0.5667, 0.5418, 0.5779, 0.5301, 0.5018, 0.5237, 0.5331, 0.5018,
        0.5221, 0.5412, 0.5186, 0.5697, 0.5200, 0.5374, 0.4886, 0.5462, 0.5385,
        0.5334, 0.5632, 0.5535, 0.5001, 0.5610, 0.5176, 0.5444, 0.5573, 0.5491,
        0.5457, 0.5399, 0.5795, 0.4930, 0.5522, 0.5268, 0.5256, 0.5224, 0.4933,
        0.5170, 0.5647, 0.5282, 0.5471, 0.5299, 0.5576, 0.5260, 0.5116, 0.5053,
        0.5105, 0.5310, 0.5316, 0.5313, 0.5211, 0.5433, 0.4741, 0.5302, 0.4994,
        0.5328, 0.5490, 0.5356, 0.5382, 0.5416, 0.5427, 0.4899, 0.4788, 0.5292,
        0.5111, 0.5119, 0.5341, 0.5110, 0.5220, 0.5238, 0.5114, 0.5268, 0.5035,
        0.5178, 0.5598, 0.6188, 0.6112, 0.6297, 0.5914, 0.5822, 0.6098, 0.5972,
        0.5793, 0.5546, 0.5439, 0.5836, 0.5087, 0.6384, 0.5124, 0.6331, 0.6191,
        0.6379, 0.6253, 0.5755, 0.6454, 0.6367, 0.6163, 0.5238, 0.6290, 0.6323,
        0.4405, 0.5312, 0.5224, 0.5356, 0.4422, 0.5724, 0.4324, 0.6181, 0.4321,
        0.6054, 0.5531, 0.5971, 0.5355, 0.4743, 0.5560, 0.5408, 0.6033, 0.6434,
        0.5992, 0.4383, 0.6331, 0.6397, 0.5495, 0.5566, 0.6159, 0.5573, 0.5036,
        0.6179, 0.5539, 0.5696, 0.4443, 0.6122, 0.6447, 0.4550, 0.6233, 0.6560,
        0.4388, 0.4753, 0.5810, 0.6089, 0.4624, 0.5718, 0.6314, 0.6283, 0.5277,
        0.6181, 0.6399, 0.6389, 0.6474, 0.5974, 0.5941, 0.6270, 0.6447, 0.5028,
        0.4349, 0.5705, 0.5839, 0.6426, 0.6031, 0.5620, 0.5096, 0.6088, 0.6536,
        0.6060, 0.4722, 0.6198, 0.4432, 0.6411, 0.5622, 0.6283, 0.6331, 0.5882,
        0.6428, 0.6067, 0.6445, 0.5770, 0.6447, 0.6117, 0.5690, 0.5810, 0.5622,
        0.6089, 0.6416, 0.5664, 0.5543, 0.5334, 0.6065, 0.6115, 0.6256, 0.6344,
        0.6195, 0.5579, 0.6275, 0.4503, 0.6084, 0.5772, 0.5515, 0.5226, 0.6330,
        0.6331, 0.6493, 0.4748, 0.6175, 0.6572, 0.5928, 0.6355, 0.6349, 0.6353,
        0.6695, 0.6037, 0.6250, 0.5876, 0.6446, 0.6170, 0.5594, 0.6146, 0.6268,
        0.5421, 0.6314, 0.5941, 0.5577, 0.6264, 0.5975, 0.6488, 0.6527, 0.5910,
        0.6111, 0.6245, 0.6489, 0.6085, 0.6041, 0.6553, 0.6085, 0.6204, 0.6403,
        0.5950, 0.6281, 0.6303, 0.6395, 0.6359, 0.6108, 0.5381, 0.6115, 0.6221,
        0.5269, 0.6162, 0.6224, 0.5490, 0.6288, 0.6160, 0.5294, 0.6583, 0.5966,
        0.6049, 0.5663, 0.6351, 0.6151, 0.5785, 0.6551, 0.6571, 0.6495, 0.6082,
        0.6212, 0.6220, 0.6025, 0.6219, 0.5652, 0.6332, 0.5718, 0.6434, 0.5699,
        0.6529, 0.5734, 0.6102, 0.6301, 0.5981, 0.6002, 0.6296, 0.5708, 0.6193,
        0.6039, 0.6597, 0.6034, 0.5672, 0.6290, 0.6162, 0.5913, 0.6254, 0.6155,
        0.6071, 0.6643, 0.6338, 0.6073, 0.5505, 0.5813, 0.5580, 0.6123, 0.6094,
        0.5500, 0.6313, 0.5396, 0.6448, 0.5937, 0.5418, 0.6394, 0.5797, 0.6368,
        0.6088, 0.5735, 0.6118, 0.6520, 0.6552, 0.6271, 0.6436, 0.5578, 0.5755,
        0.6347, 0.6170, 0.6345, 0.6267, 0.6242, 0.6599, 0.6558, 0.6137, 0.6050,
        0.6174, 0.5227, 0.6234, 0.6302, 0.6345, 0.6083], dtype=torch.float64)
2023-05-09 12:35:53,804 :: INFO :: Epoch 5: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.009770270437002182, V.norm 0.011513358913362026, MLP.norm 0.0005819871439598501
2023-05-09 12:36:12,819 :: INFO :: log info to logs/tiktok_Attention.log
2023-05-09 12:36:12,819 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=128, dataset='tiktok', device='cuda:0', epoch=5, f_epoch=20, f_max=10, feat_dim=32, ite=5, lam=0.1, lr=0.001, model='Attention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=0, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=256, tolog=1, wdi=2)
2023-05-09 12:36:14,398 :: INFO :: torch.Size([76083, 384])
2023-05-09 12:36:34,398 :: INFO :: ERM mask: from pre-train tensor([0.5523, 0.5259, 0.5222, 0.5572, 0.5327, 0.5070, 0.5500, 0.5492, 0.5193,
        0.5253, 0.5332, 0.4896, 0.5381, 0.5486, 0.5384, 0.5155, 0.5169, 0.5520,
        0.5182, 0.5483, 0.5210, 0.5311, 0.5536, 0.5246, 0.5053, 0.5231, 0.5224,
        0.5452, 0.5878, 0.5132, 0.5371, 0.5449, 0.5574, 0.5425, 0.4957, 0.4715,
        0.5335, 0.5379, 0.5006, 0.5452, 0.4860, 0.5240, 0.5384, 0.5114, 0.5147,
        0.5179, 0.5337, 0.5109, 0.5339, 0.5208, 0.5157, 0.5156, 0.5030, 0.5171,
        0.5412, 0.5667, 0.5418, 0.5779, 0.5301, 0.5018, 0.5237, 0.5331, 0.5018,
        0.5221, 0.5412, 0.5186, 0.5697, 0.5200, 0.5374, 0.4886, 0.5462, 0.5385,
        0.5334, 0.5632, 0.5535, 0.5001, 0.5610, 0.5176, 0.5444, 0.5573, 0.5491,
        0.5457, 0.5399, 0.5795, 0.4930, 0.5522, 0.5268, 0.5256, 0.5224, 0.4933,
        0.5170, 0.5647, 0.5282, 0.5471, 0.5299, 0.5576, 0.5260, 0.5116, 0.5053,
        0.5105, 0.5310, 0.5316, 0.5313, 0.5211, 0.5433, 0.4741, 0.5302, 0.4994,
        0.5328, 0.5490, 0.5356, 0.5382, 0.5416, 0.5427, 0.4899, 0.4788, 0.5292,
        0.5111, 0.5119, 0.5341, 0.5110, 0.5220, 0.5238, 0.5114, 0.5268, 0.5035,
        0.5178, 0.5598, 0.6188, 0.6112, 0.6297, 0.5914, 0.5822, 0.6098, 0.5972,
        0.5793, 0.5546, 0.5439, 0.5836, 0.5087, 0.6384, 0.5124, 0.6331, 0.6191,
        0.6379, 0.6253, 0.5755, 0.6454, 0.6367, 0.6163, 0.5238, 0.6290, 0.6323,
        0.4405, 0.5312, 0.5224, 0.5356, 0.4422, 0.5724, 0.4324, 0.6181, 0.4321,
        0.6054, 0.5531, 0.5971, 0.5355, 0.4743, 0.5560, 0.5408, 0.6033, 0.6434,
        0.5992, 0.4383, 0.6331, 0.6397, 0.5495, 0.5566, 0.6159, 0.5573, 0.5036,
        0.6179, 0.5539, 0.5696, 0.4443, 0.6122, 0.6447, 0.4550, 0.6233, 0.6560,
        0.4388, 0.4753, 0.5810, 0.6089, 0.4624, 0.5718, 0.6314, 0.6283, 0.5277,
        0.6181, 0.6399, 0.6389, 0.6474, 0.5974, 0.5941, 0.6270, 0.6447, 0.5028,
        0.4349, 0.5705, 0.5839, 0.6426, 0.6031, 0.5620, 0.5096, 0.6088, 0.6536,
        0.6060, 0.4722, 0.6198, 0.4432, 0.6411, 0.5622, 0.6283, 0.6331, 0.5882,
        0.6428, 0.6067, 0.6445, 0.5770, 0.6447, 0.6117, 0.5690, 0.5810, 0.5622,
        0.6089, 0.6416, 0.5664, 0.5543, 0.5334, 0.6065, 0.6115, 0.6256, 0.6344,
        0.6195, 0.5579, 0.6275, 0.4503, 0.6084, 0.5772, 0.5515, 0.5226, 0.6330,
        0.6331, 0.6493, 0.4748, 0.6175, 0.6572, 0.5928, 0.6355, 0.6349, 0.6353,
        0.6695, 0.6037, 0.6250, 0.5876, 0.6446, 0.6170, 0.5594, 0.6146, 0.6268,
        0.5421, 0.6314, 0.5941, 0.5577, 0.6264, 0.5975, 0.6488, 0.6527, 0.5910,
        0.6111, 0.6245, 0.6489, 0.6085, 0.6041, 0.6553, 0.6085, 0.6204, 0.6403,
        0.5950, 0.6281, 0.6303, 0.6395, 0.6359, 0.6108, 0.5381, 0.6115, 0.6221,
        0.5269, 0.6162, 0.6224, 0.5490, 0.6288, 0.6160, 0.5294, 0.6583, 0.5966,
        0.6049, 0.5663, 0.6351, 0.6151, 0.5785, 0.6551, 0.6571, 0.6495, 0.6082,
        0.6212, 0.6220, 0.6025, 0.6219, 0.5652, 0.6332, 0.5718, 0.6434, 0.5699,
        0.6529, 0.5734, 0.6102, 0.6301, 0.5981, 0.6002, 0.6296, 0.5708, 0.6193,
        0.6039, 0.6597, 0.6034, 0.5672, 0.6290, 0.6162, 0.5913, 0.6254, 0.6155,
        0.6071, 0.6643, 0.6338, 0.6073, 0.5505, 0.5813, 0.5580, 0.6123, 0.6094,
        0.5500, 0.6313, 0.5396, 0.6448, 0.5937, 0.5418, 0.6394, 0.5797, 0.6368,
        0.6088, 0.5735, 0.6118, 0.6520, 0.6552, 0.6271, 0.6436, 0.5578, 0.5755,
        0.6347, 0.6170, 0.6345, 0.6267, 0.6242, 0.6599, 0.6558, 0.6137, 0.6050,
        0.6174, 0.5227, 0.6234, 0.6302, 0.6345, 0.6083], dtype=torch.float64)
2023-05-09 12:42:53,976 :: INFO :: log info to logs/tiktok_Attention.log
2023-05-09 12:42:53,976 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=256, dataset='tiktok', device='cuda:0', epoch=5, f_epoch=20, f_max=10, feat_dim=32, ite=5, lam=0.1, lr=0.001, model='Attention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=0, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=128, tolog=1, wdi=2)
2023-05-09 12:42:55,570 :: INFO :: torch.Size([76083, 384])
2023-05-09 12:43:15,835 :: INFO :: ERM mask: from pre-train tensor([0.5523, 0.5259, 0.5222, 0.5572, 0.5327, 0.5070, 0.5500, 0.5492, 0.5193,
        0.5253, 0.5332, 0.4896, 0.5381, 0.5486, 0.5384, 0.5155, 0.5169, 0.5520,
        0.5182, 0.5483, 0.5210, 0.5311, 0.5536, 0.5246, 0.5053, 0.5231, 0.5224,
        0.5452, 0.5878, 0.5132, 0.5371, 0.5449, 0.5574, 0.5425, 0.4957, 0.4715,
        0.5335, 0.5379, 0.5006, 0.5452, 0.4860, 0.5240, 0.5384, 0.5114, 0.5147,
        0.5179, 0.5337, 0.5109, 0.5339, 0.5208, 0.5157, 0.5156, 0.5030, 0.5171,
        0.5412, 0.5667, 0.5418, 0.5779, 0.5301, 0.5018, 0.5237, 0.5331, 0.5018,
        0.5221, 0.5412, 0.5186, 0.5697, 0.5200, 0.5374, 0.4886, 0.5462, 0.5385,
        0.5334, 0.5632, 0.5535, 0.5001, 0.5610, 0.5176, 0.5444, 0.5573, 0.5491,
        0.5457, 0.5399, 0.5795, 0.4930, 0.5522, 0.5268, 0.5256, 0.5224, 0.4933,
        0.5170, 0.5647, 0.5282, 0.5471, 0.5299, 0.5576, 0.5260, 0.5116, 0.5053,
        0.5105, 0.5310, 0.5316, 0.5313, 0.5211, 0.5433, 0.4741, 0.5302, 0.4994,
        0.5328, 0.5490, 0.5356, 0.5382, 0.5416, 0.5427, 0.4899, 0.4788, 0.5292,
        0.5111, 0.5119, 0.5341, 0.5110, 0.5220, 0.5238, 0.5114, 0.5268, 0.5035,
        0.5178, 0.5598, 0.6188, 0.6112, 0.6297, 0.5914, 0.5822, 0.6098, 0.5972,
        0.5793, 0.5546, 0.5439, 0.5836, 0.5087, 0.6384, 0.5124, 0.6331, 0.6191,
        0.6379, 0.6253, 0.5755, 0.6454, 0.6367, 0.6163, 0.5238, 0.6290, 0.6323,
        0.4405, 0.5312, 0.5224, 0.5356, 0.4422, 0.5724, 0.4324, 0.6181, 0.4321,
        0.6054, 0.5531, 0.5971, 0.5355, 0.4743, 0.5560, 0.5408, 0.6033, 0.6434,
        0.5992, 0.4383, 0.6331, 0.6397, 0.5495, 0.5566, 0.6159, 0.5573, 0.5036,
        0.6179, 0.5539, 0.5696, 0.4443, 0.6122, 0.6447, 0.4550, 0.6233, 0.6560,
        0.4388, 0.4753, 0.5810, 0.6089, 0.4624, 0.5718, 0.6314, 0.6283, 0.5277,
        0.6181, 0.6399, 0.6389, 0.6474, 0.5974, 0.5941, 0.6270, 0.6447, 0.5028,
        0.4349, 0.5705, 0.5839, 0.6426, 0.6031, 0.5620, 0.5096, 0.6088, 0.6536,
        0.6060, 0.4722, 0.6198, 0.4432, 0.6411, 0.5622, 0.6283, 0.6331, 0.5882,
        0.6428, 0.6067, 0.6445, 0.5770, 0.6447, 0.6117, 0.5690, 0.5810, 0.5622,
        0.6089, 0.6416, 0.5664, 0.5543, 0.5334, 0.6065, 0.6115, 0.6256, 0.6344,
        0.6195, 0.5579, 0.6275, 0.4503, 0.6084, 0.5772, 0.5515, 0.5226, 0.6330,
        0.6331, 0.6493, 0.4748, 0.6175, 0.6572, 0.5928, 0.6355, 0.6349, 0.6353,
        0.6695, 0.6037, 0.6250, 0.5876, 0.6446, 0.6170, 0.5594, 0.6146, 0.6268,
        0.5421, 0.6314, 0.5941, 0.5577, 0.6264, 0.5975, 0.6488, 0.6527, 0.5910,
        0.6111, 0.6245, 0.6489, 0.6085, 0.6041, 0.6553, 0.6085, 0.6204, 0.6403,
        0.5950, 0.6281, 0.6303, 0.6395, 0.6359, 0.6108, 0.5381, 0.6115, 0.6221,
        0.5269, 0.6162, 0.6224, 0.5490, 0.6288, 0.6160, 0.5294, 0.6583, 0.5966,
        0.6049, 0.5663, 0.6351, 0.6151, 0.5785, 0.6551, 0.6571, 0.6495, 0.6082,
        0.6212, 0.6220, 0.6025, 0.6219, 0.5652, 0.6332, 0.5718, 0.6434, 0.5699,
        0.6529, 0.5734, 0.6102, 0.6301, 0.5981, 0.6002, 0.6296, 0.5708, 0.6193,
        0.6039, 0.6597, 0.6034, 0.5672, 0.6290, 0.6162, 0.5913, 0.6254, 0.6155,
        0.6071, 0.6643, 0.6338, 0.6073, 0.5505, 0.5813, 0.5580, 0.6123, 0.6094,
        0.5500, 0.6313, 0.5396, 0.6448, 0.5937, 0.5418, 0.6394, 0.5797, 0.6368,
        0.6088, 0.5735, 0.6118, 0.6520, 0.6552, 0.6271, 0.6436, 0.5578, 0.5755,
        0.6347, 0.6170, 0.6345, 0.6267, 0.6242, 0.6599, 0.6558, 0.6137, 0.6050,
        0.6174, 0.5227, 0.6234, 0.6302, 0.6345, 0.6083], dtype=torch.float64)
2023-05-09 12:43:33,585 :: INFO :: Epoch 5: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.009770270437002182, V.norm 0.011513358913362026, MLP.norm 0.0005819871439598501
2023-05-09 12:44:28,445 :: INFO :: ----- val -----
2023-05-09 12:44:28,445 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 12:44:28,445 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 12:44:28,445 :: INFO :: ndcg [0.0, 0.0, 1.2793309418804509e-05]
2023-05-09 12:45:23,694 :: INFO :: ----- test -----
2023-05-09 12:45:23,694 :: INFO :: Precision [0.0, 1.0917626507997163e-05, 5.458813253998581e-06]
2023-05-09 12:45:23,694 :: INFO :: Recall [0.0, 5.458813253998581e-05, 5.458813253998581e-05]
2023-05-09 12:45:23,694 :: INFO :: ndcg [0.0, 2.1117572314784737e-05, 2.1117572314784737e-05]
2023-05-09 12:45:29,585 :: INFO :: Epoch 10: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 2.462642441969365e-05, V.norm 2.9048382202745415e-05, MLP.norm 1.4902383327353164e-06
2023-05-09 12:46:25,070 :: INFO :: ----- val -----
2023-05-09 12:46:25,070 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 12:46:25,070 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 12:46:25,070 :: INFO :: ndcg [0.0, 0.0, 1.3322858847708838e-05]
2023-05-09 12:47:19,679 :: INFO :: ----- test -----
2023-05-09 12:47:19,679 :: INFO :: Precision [0.0, 0.0, 2.7294066269992907e-06]
2023-05-09 12:47:19,679 :: INFO :: Recall [0.0, 0.0, 2.7294066269992904e-05]
2023-05-09 12:47:19,679 :: INFO :: ndcg [0.0, 0.0, 9.098022089997634e-06]
2023-05-09 12:47:25,445 :: INFO :: Epoch 15: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 6.051975987020342e-08, V.norm 7.146434910509925e-08, MLP.norm 3.6609961728828466e-09
2023-05-09 12:48:19,961 :: INFO :: ----- val -----
2023-05-09 12:48:19,961 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 12:48:19,961 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 12:48:19,961 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 12:49:14,194 :: INFO :: ----- test -----
2023-05-09 12:49:14,194 :: INFO :: Precision [0.0, 5.458813253998581e-06, 8.188219880997872e-06]
2023-05-09 12:49:14,194 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 8.18821988099787e-05]
2023-05-09 12:49:14,194 :: INFO :: ndcg [0.0, 1.3647033134996452e-05, 3.08676716406861e-05]
2023-05-09 12:49:19,898 :: INFO :: Epoch 20: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 1.4722492669427822e-10, V.norm 1.73727879304586e-10, MLP.norm 8.995852673887583e-12
2023-05-09 12:50:14,163 :: INFO :: ----- val -----
2023-05-09 12:50:14,163 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 12:50:14,163 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 12:50:14,163 :: INFO :: ndcg [0.0, 0.0, 1.3961711740904128e-05]
2023-05-09 12:51:10,366 :: INFO :: ----- test -----
2023-05-09 12:51:10,366 :: INFO :: Precision [0.0, 5.458813253998581e-06, 2.7294066269992907e-06]
2023-05-09 12:51:10,366 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 2.7294066269992904e-05]
2023-05-09 12:51:10,366 :: INFO :: ndcg [0.0, 1.0558786157392369e-05, 1.0558786157392369e-05]
2023-05-09 12:51:16,210 :: INFO :: Epoch 25: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 3.550328976122119e-13, V.norm 4.2008388954906106e-13, MLP.norm 2.159724798360494e-14
2023-05-09 12:52:08,445 :: INFO :: ----- val -----
2023-05-09 12:52:08,445 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 12:52:08,445 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 12:52:08,445 :: INFO :: ndcg [0.0, 0.0, 1.3961711740904128e-05]
2023-05-09 12:53:01,085 :: INFO :: ----- test -----
2023-05-09 12:53:01,085 :: INFO :: Precision [0.0, 1.0917626507997163e-05, 1.3647033134996452e-05]
2023-05-09 12:53:01,085 :: INFO :: Recall [0.0, 5.458813253998581e-05, 0.00013647033134996453]
2023-05-09 12:53:01,085 :: INFO :: ndcg [0.0, 2.5401947651984092e-05, 4.9397789354581314e-05]
2023-05-09 12:53:06,945 :: INFO :: Epoch 30: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 8.551658929160401e-16, V.norm 1.0109702449647394e-15, MLP.norm 5.1804488731958706e-17
2023-05-09 12:54:00,569 :: INFO :: ----- val -----
2023-05-09 12:54:00,569 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 12:54:00,569 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 12:54:00,569 :: INFO :: ndcg [0.0, 0.0, 1.2793309418804509e-05]
2023-05-09 12:54:54,835 :: INFO :: ----- test -----
2023-05-09 12:54:54,835 :: INFO :: Precision [0.0, 1.6376439761995743e-05, 1.3647033134996452e-05]
2023-05-09 12:54:54,835 :: INFO :: Recall [0.0, 8.18821988099787e-05, 0.00013647033134996453]
2023-05-09 12:54:54,835 :: INFO :: ndcg [0.0, 3.596073380937646e-05, 5.3899409031058956e-05]
2023-05-09 12:55:00,744 :: INFO :: Epoch 35: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 2.049087263922991e-18, V.norm 2.4256051963012565e-18, MLP.norm 1.236366440561638e-19
2023-05-09 12:55:57,085 :: INFO :: ----- val -----
2023-05-09 12:55:57,085 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 12:55:57,085 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 12:55:57,085 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 12:56:51,744 :: INFO :: ----- test -----
2023-05-09 12:56:51,744 :: INFO :: Precision [0.0, 1.0917626507997163e-05, 8.188219880997872e-06]
2023-05-09 12:56:51,744 :: INFO :: Recall [0.0, 5.458813253998581e-05, 8.18821988099787e-05]
2023-05-09 12:56:51,744 :: INFO :: ndcg [0.0, 2.7294066269992904e-05, 3.6392088359990535e-05]
2023-05-09 12:56:57,572 :: INFO :: Epoch 40: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 1.6740958743820435e-22, V.norm 1.9087629348058244e-22, MLP.norm 3.743392066509216e-23
2023-05-09 12:57:53,337 :: INFO :: ----- val -----
2023-05-09 12:57:53,337 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 12:57:53,337 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 12:57:53,337 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 12:58:48,228 :: INFO :: ----- test -----
2023-05-09 12:58:48,228 :: INFO :: Precision [0.0, 5.458813253998581e-06, 8.188219880997872e-06]
2023-05-09 12:58:48,228 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 6.823516567498226e-05]
2023-05-09 12:58:48,228 :: INFO :: ndcg [0.0, 2.7294066269992904e-05, 2.817088325401091e-05]
2023-05-09 12:58:54,181 :: INFO :: Epoch 45: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0, MLP.norm 0.0
2023-05-09 12:59:48,541 :: INFO :: ----- val -----
2023-05-09 12:59:48,541 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 12:59:48,541 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 12:59:48,541 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 13:00:42,384 :: INFO :: ----- test -----
2023-05-09 13:00:42,384 :: INFO :: Precision [0.0, 5.458813253998581e-06, 8.188219880997872e-06]
2023-05-09 13:00:42,384 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 6.823516567498226e-05]
2023-05-09 13:00:42,384 :: INFO :: ndcg [0.0, 2.7294066269992904e-05, 2.817088325401091e-05]
2023-05-09 13:00:48,058 :: INFO :: Epoch 50: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0, MLP.norm 0.0
2023-05-09 13:01:42,167 :: INFO :: ----- val -----
2023-05-09 13:01:42,167 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 13:01:42,167 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 13:01:42,167 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 13:02:37,761 :: INFO :: ----- test -----
2023-05-09 13:02:37,761 :: INFO :: Precision [0.0, 5.458813253998581e-06, 8.188219880997872e-06]
2023-05-09 13:02:37,761 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 6.823516567498226e-05]
2023-05-09 13:02:37,761 :: INFO :: ndcg [0.0, 2.7294066269992904e-05, 2.817088325401091e-05]
2023-05-09 13:02:43,636 :: INFO :: Epoch 55: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0, MLP.norm 9.061725165810525e-14
2023-05-09 13:03:41,591 :: INFO :: ----- val -----
2023-05-09 13:03:41,591 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 13:03:41,591 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 13:03:41,591 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 13:04:38,591 :: INFO :: ----- test -----
2023-05-09 13:04:38,591 :: INFO :: Precision [0.0, 5.458813253998581e-06, 8.188219880997872e-06]
2023-05-09 13:04:38,591 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 6.823516567498226e-05]
2023-05-09 13:04:38,591 :: INFO :: ndcg [0.0, 2.7294066269992904e-05, 2.817088325401091e-05]
2023-05-09 13:04:44,435 :: INFO :: Epoch 60: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0, MLP.norm 0.0011874802876263857
2023-05-09 13:05:38,748 :: INFO :: ----- val -----
2023-05-09 13:05:38,748 :: INFO :: Precision [0.0, 0.0, 8.851515822084533e-06]
2023-05-09 13:05:38,748 :: INFO :: Recall [0.0, 0.0, 8.851515822084532e-05]
2023-05-09 13:05:38,748 :: INFO :: ndcg [0.0, 0.0, 2.5586618837609017e-05]
2023-05-09 13:06:32,484 :: INFO :: ----- test -----
2023-05-09 13:06:32,484 :: INFO :: Precision [0.0, 5.458813253998581e-06, 1.637643976199574e-05]
2023-05-09 13:06:32,484 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 0.0001637643976199574]
2023-05-09 13:06:32,484 :: INFO :: ndcg [0.0, 1.0558786157392369e-05, 5.458326008491455e-05]
2023-05-09 13:06:38,343 :: INFO :: Epoch 65: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0, MLP.norm 0.0011640415759757161
2023-05-09 13:07:32,078 :: INFO :: ----- val -----
2023-05-09 13:07:32,078 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 13:07:32,078 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 13:07:32,078 :: INFO :: ndcg [0.0, 0.0, 1.5764867763134417e-05]
2023-05-09 13:08:27,156 :: INFO :: ----- test -----
2023-05-09 13:08:27,156 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 13:08:27,156 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 13:08:27,156 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 13:08:33,109 :: INFO :: Epoch 70: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0, MLP.norm 0.0011022815015166998
2023-05-09 13:09:27,531 :: INFO :: ----- val -----
2023-05-09 13:09:27,531 :: INFO :: Precision [0.0, 8.851515822084533e-06, 1.32772737331268e-05]
2023-05-09 13:09:27,531 :: INFO :: Recall [0.0, 4.425757911042266e-05, 0.00013277273733126798]
2023-05-09 13:09:27,531 :: INFO :: ndcg [0.0, 1.7121168720271814e-05, 4.323733698678516e-05]
2023-05-09 13:10:23,000 :: INFO :: ----- test -----
2023-05-09 13:10:23,000 :: INFO :: Precision [0.0, 1.6376439761995743e-05, 1.637643976199574e-05]
2023-05-09 13:10:23,000 :: INFO :: Recall [0.0, 8.18821988099787e-05, 0.0001637643976199574]
2023-05-09 13:10:23,000 :: INFO :: ndcg [0.0, 4.5000063168771676e-05, 7.291844991954106e-05]
2023-05-09 13:10:28,968 :: INFO :: Epoch 75: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0, MLP.norm 0.0012304242700338364
2023-05-09 13:11:23,625 :: INFO :: ----- val -----
2023-05-09 13:11:23,625 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 13:11:23,625 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 13:11:23,625 :: INFO :: ndcg [0.0, 0.0, 1.2793309418804509e-05]
2023-05-09 13:12:18,172 :: INFO :: ----- test -----
2023-05-09 13:12:18,172 :: INFO :: Precision [0.0, 1.6376439761995743e-05, 2.456465964299361e-05]
2023-05-09 13:12:18,172 :: INFO :: Recall [0.0, 8.18821988099787e-05, 0.0002456465964299361]
2023-05-09 13:12:18,172 :: INFO :: ndcg [0.0, 3.596073380937646e-05, 9.174096009636299e-05]
2023-05-09 13:12:23,999 :: INFO :: Epoch 80: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0, MLP.norm 0.001238734694197774
2023-05-09 13:13:19,093 :: INFO :: ----- val -----
2023-05-09 13:13:19,093 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 13:13:19,093 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 13:13:19,093 :: INFO :: ndcg [0.0, 0.0, 1.4752526370140887e-05]
2023-05-09 13:14:12,719 :: INFO :: ----- test -----
2023-05-09 13:14:12,719 :: INFO :: Precision [0.0, 0.0, 5.458813253998581e-06]
2023-05-09 13:14:12,719 :: INFO :: Recall [0.0, 0.0, 5.458813253998581e-05]
2023-05-09 13:14:12,719 :: INFO :: ndcg [0.0, 0.0, 1.833266182361895e-05]
2023-05-09 13:14:18,360 :: INFO :: Epoch 85: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0, MLP.norm 0.0012542895274236798
2023-05-09 13:15:10,594 :: INFO :: ----- val -----
2023-05-09 13:15:10,594 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 13:15:10,594 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 13:15:10,594 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 13:16:03,213 :: INFO :: ----- test -----
2023-05-09 13:16:03,213 :: INFO :: Precision [0.0, 5.458813253998581e-06, 5.458813253998581e-06]
2023-05-09 13:16:03,213 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 5.458813253998581e-05]
2023-05-09 13:16:03,213 :: INFO :: ndcg [0.0, 1.7220638505689654e-05, 2.5110393031534075e-05]
2023-05-09 13:16:08,838 :: INFO :: Epoch 90: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0, MLP.norm 0.0016105335671454668
2023-05-09 13:17:03,260 :: INFO :: ----- val -----
2023-05-09 13:17:03,260 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 13:17:03,260 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 13:17:03,260 :: INFO :: ndcg [0.0, 0.0, 1.3961711740904128e-05]
2023-05-09 13:17:57,526 :: INFO :: ----- test -----
2023-05-09 13:17:57,526 :: INFO :: Precision [0.0, 1.0917626507997163e-05, 1.0917626507997163e-05]
2023-05-09 13:17:57,526 :: INFO :: Recall [0.0, 5.458813253998581e-05, 0.00010917626507997162]
2023-05-09 13:17:57,526 :: INFO :: ndcg [0.0, 2.1117572314784737e-05, 3.9089354184380295e-05]
2023-05-09 13:18:03,401 :: INFO :: Epoch 95: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0, MLP.norm 0.0011949132895097136
2023-05-09 13:18:58,807 :: INFO :: ----- val -----
2023-05-09 13:18:58,807 :: INFO :: Precision [0.0, 0.0, 8.851515822084533e-06]
2023-05-09 13:18:58,807 :: INFO :: Recall [0.0, 0.0, 8.851515822084532e-05]
2023-05-09 13:18:58,807 :: INFO :: ndcg [0.0, 0.0, 2.5586618837609017e-05]
2023-05-09 13:19:54,741 :: INFO :: ----- test -----
2023-05-09 13:19:54,741 :: INFO :: Precision [0.0, 1.6376439761995743e-05, 1.3647033134996452e-05]
2023-05-09 13:19:54,741 :: INFO :: Recall [0.0, 8.18821988099787e-05, 0.00013647033134996453]
2023-05-09 13:19:54,741 :: INFO :: ndcg [0.0, 4.619619152836695e-05, 5.15912573535344e-05]
2023-05-09 13:20:00,756 :: INFO :: Epoch 100: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0, MLP.norm 0.001250851433724165
2023-05-09 13:20:55,943 :: INFO :: ----- val -----
2023-05-09 13:20:55,943 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 13:20:55,943 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 13:20:55,943 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 13:21:50,444 :: INFO :: ----- test -----
2023-05-09 13:21:50,444 :: INFO :: Precision [0.0, 2.1835253015994326e-05, 2.1835253015994322e-05]
2023-05-09 13:21:50,444 :: INFO :: Recall [0.0, 0.00010917626507997162, 0.00021835253015994323]
2023-05-09 13:21:50,444 :: INFO :: ndcg [0.0, 5.507349093307493e-05, 9.050838439175812e-05]
2023-05-09 13:21:56,146 :: INFO :: Epoch 105: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0, MLP.norm 0.0011035866336897016
2023-05-09 13:22:54,647 :: INFO :: ----- val -----
2023-05-09 13:22:54,647 :: INFO :: Precision [0.0, 0.0, 1.32772737331268e-05]
2023-05-09 13:22:54,647 :: INFO :: Recall [0.0, 0.0, 0.00013277273733126798]
2023-05-09 13:22:54,647 :: INFO :: ndcg [0.0, 0.0, 4.526992050341619e-05]
2023-05-09 13:23:50,053 :: INFO :: ----- test -----
2023-05-09 13:23:50,053 :: INFO :: Precision [0.0, 5.458813253998581e-06, 5.458813253998581e-06]
2023-05-09 13:23:50,053 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 5.458813253998581e-05]
2023-05-09 13:23:50,053 :: INFO :: ndcg [0.0, 1.0558786157392369e-05, 1.844854068323679e-05]
2023-05-09 13:23:56,006 :: INFO :: Epoch 110: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0, MLP.norm 0.0012372490018606186
2023-05-09 13:24:53,162 :: INFO :: ----- val -----
2023-05-09 13:24:53,162 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 13:24:53,162 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 13:24:53,162 :: INFO :: ndcg [0.0, 0.0, 1.4752526370140887e-05]
2023-05-09 13:25:47,852 :: INFO :: ----- test -----
2023-05-09 13:25:47,852 :: INFO :: Precision [0.0, 0.0, 8.188219880997872e-06]
2023-05-09 13:25:47,852 :: INFO :: Recall [0.0, 0.0, 8.18821988099787e-05]
2023-05-09 13:25:47,852 :: INFO :: ndcg [0.0, 0.0, 2.5042984554661586e-05]
2023-05-09 13:25:53,633 :: INFO :: Epoch 115: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0, MLP.norm 0.0014067536685615778
2023-05-09 13:26:47,602 :: INFO :: ----- val -----
2023-05-09 13:26:47,602 :: INFO :: Precision [0.0, 0.0, 8.851515822084533e-06]
2023-05-09 13:26:47,602 :: INFO :: Recall [0.0, 0.0, 8.851515822084532e-05]
2023-05-09 13:26:47,602 :: INFO :: ndcg [0.0, 0.0, 2.754583578894539e-05]
2023-05-09 13:27:41,586 :: INFO :: ----- test -----
2023-05-09 13:27:41,586 :: INFO :: Precision [0.0, 1.0917626507997163e-05, 8.188219880997872e-06]
2023-05-09 13:27:41,586 :: INFO :: Recall [0.0, 5.458813253998581e-05, 8.18821988099787e-05]
2023-05-09 13:27:41,586 :: INFO :: ndcg [0.0, 2.5401947651984092e-05, 3.596073380937646e-05]
2023-05-09 13:27:47,461 :: INFO :: Epoch 120: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0, MLP.norm 0.0014542959397658706
2023-05-09 13:28:41,867 :: INFO :: ----- val -----
2023-05-09 13:28:41,867 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 13:28:41,867 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 13:28:41,867 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 13:29:37,820 :: INFO :: ----- test -----
2023-05-09 13:29:37,820 :: INFO :: Precision [0.0, 0.0, 8.188219880997872e-06]
2023-05-09 13:29:37,820 :: INFO :: Recall [0.0, 0.0, 8.18821988099787e-05]
2023-05-09 13:29:37,820 :: INFO :: ndcg [0.0, 0.0, 2.7385438061145575e-05]
2023-05-09 13:29:43,570 :: INFO :: Epoch 125: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0, MLP.norm 0.001421201042830944
2023-05-09 13:30:37,476 :: INFO :: ----- val -----
2023-05-09 13:30:37,476 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 13:30:37,476 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 13:30:37,476 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 13:31:32,617 :: INFO :: ----- test -----
2023-05-09 13:31:32,617 :: INFO :: Precision [2.7294066269992904e-05, 5.458813253998581e-06, 1.3647033134996452e-05]
2023-05-09 13:31:32,617 :: INFO :: Recall [2.7294066269992904e-05, 2.7294066269992904e-05, 0.00013647033134996453]
2023-05-09 13:31:32,617 :: INFO :: ndcg [2.7294066269992904e-05, 2.7294066269992904e-05, 5.652211579591172e-05]
2023-05-09 13:31:38,320 :: INFO :: Epoch 130: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0, MLP.norm 0.00179652264341712
2023-05-09 13:32:31,664 :: INFO :: ----- val -----
2023-05-09 13:32:31,664 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 13:32:31,664 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 13:32:31,664 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 13:33:27,370 :: INFO :: ----- test -----
2023-05-09 13:33:27,370 :: INFO :: Precision [0.0, 0.0, 2.7294066269992907e-06]
2023-05-09 13:33:27,370 :: INFO :: Recall [0.0, 0.0, 2.7294066269992904e-05]
2023-05-09 13:33:27,370 :: INFO :: ndcg [0.0, 0.0, 1.0558786157392369e-05]
2023-05-09 13:33:33,057 :: INFO :: Epoch 135: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0, MLP.norm 0.0019852654077112675
2023-05-09 13:34:26,245 :: INFO :: ----- val -----
2023-05-09 13:34:26,245 :: INFO :: Precision [0.0, 0.0, 8.851515822084533e-06]
2023-05-09 13:34:26,245 :: INFO :: Recall [0.0, 0.0, 8.851515822084532e-05]
2023-05-09 13:34:26,245 :: INFO :: ndcg [0.0, 0.0, 2.8714238111045017e-05]
2023-05-09 13:35:21,463 :: INFO :: ----- test -----
2023-05-09 13:35:21,463 :: INFO :: Precision [0.0, 5.458813253998581e-06, 1.637643976199574e-05]
2023-05-09 13:35:21,463 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 0.00015011736448496097]
2023-05-09 13:35:21,463 :: INFO :: ndcg [0.0, 1.7220638505689654e-05, 6.0757409596059037e-05]
2023-05-09 13:35:27,401 :: INFO :: Epoch 140: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0, MLP.norm 0.0017755500739440322
2023-05-09 13:36:24,231 :: INFO :: ----- val -----
2023-05-09 13:36:24,231 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 13:36:24,231 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 13:36:24,231 :: INFO :: ndcg [0.0, 0.0, 1.2793309418804509e-05]
2023-05-09 13:37:19,356 :: INFO :: ----- test -----
2023-05-09 13:37:19,356 :: INFO :: Precision [0.0, 0.0, 8.188219880997872e-06]
2023-05-09 13:37:19,356 :: INFO :: Recall [0.0, 0.0, 8.18821988099787e-05]
2023-05-09 13:37:19,356 :: INFO :: ndcg [0.0, 0.0, 2.6222416349463367e-05]
2023-05-09 13:37:25,262 :: INFO :: Epoch 145: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0, MLP.norm 0.0017130282940343022
2023-05-09 13:38:18,341 :: INFO :: ----- val -----
2023-05-09 13:38:18,341 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 13:38:18,341 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 13:38:18,341 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 13:39:13,075 :: INFO :: ----- test -----
2023-05-09 13:39:13,075 :: INFO :: Precision [0.0, 5.458813253998581e-06, 8.188219880997872e-06]
2023-05-09 13:39:13,075 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 8.18821988099787e-05]
2023-05-09 13:39:13,075 :: INFO :: ndcg [0.0, 1.1754914516987637e-05, 3.158570835667895e-05]
2023-05-09 13:39:19,059 :: INFO :: Epoch 150: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0, MLP.norm 0.0017711068503558636
2023-05-09 13:40:13,200 :: INFO :: ----- val -----
2023-05-09 13:40:13,216 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 13:40:13,216 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 13:40:13,216 :: INFO :: ndcg [0.0, 0.0, 1.3961711740904128e-05]
2023-05-09 13:41:06,622 :: INFO :: ----- test -----
2023-05-09 13:41:06,622 :: INFO :: Precision [0.0, 2.1835253015994326e-05, 1.3647033134996452e-05]
2023-05-09 13:41:06,622 :: INFO :: Recall [0.0, 0.00010917626507997162, 0.00013647033134996453]
2023-05-09 13:41:06,622 :: INFO :: ndcg [0.0, 4.960776694437291e-05, 5.8693649829812595e-05]
2023-05-09 13:41:12,356 :: INFO :: Epoch 155: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0, MLP.norm 0.0018197373719885945
2023-05-09 13:42:06,326 :: INFO :: ----- val -----
2023-05-09 13:42:06,326 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 13:42:06,326 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 13:42:06,326 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 13:43:00,967 :: INFO :: ----- test -----
2023-05-09 13:43:00,967 :: INFO :: Precision [0.0, 1.0917626507997163e-05, 1.0917626507997163e-05]
2023-05-09 13:43:00,967 :: INFO :: Recall [0.0, 5.458813253998581e-05, 9.552923194497516e-05]
2023-05-09 13:43:00,967 :: INFO :: ndcg [0.0, 2.1117572314784737e-05, 3.678120250685574e-05]
2023-05-09 13:43:06,702 :: INFO :: Epoch 160: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0, MLP.norm 0.0016893809661269188
2023-05-09 13:44:00,389 :: INFO :: ----- val -----
2023-05-09 13:44:00,389 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 13:44:00,389 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 13:44:00,389 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 13:44:55,486 :: INFO :: ----- test -----
2023-05-09 13:44:55,486 :: INFO :: Precision [0.0, 5.458813253998581e-06, 5.458813253998581e-06]
2023-05-09 13:44:55,486 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 5.458813253998581e-05]
2023-05-09 13:44:55,486 :: INFO :: ndcg [0.0, 1.0558786157392369e-05, 1.9656808247390002e-05]
2023-05-09 13:45:01,235 :: INFO :: Epoch 165: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0, MLP.norm 0.0021255980245769024
2023-05-09 13:45:57,079 :: INFO :: ----- val -----
2023-05-09 13:45:57,079 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 13:45:57,079 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 13:45:57,079 :: INFO :: ndcg [0.0, 0.0, 1.3322858847708838e-05]
2023-05-09 13:46:51,329 :: INFO :: ----- test -----
2023-05-09 13:46:51,329 :: INFO :: Precision [5.458813253998581e-05, 2.1835253015994326e-05, 3.275287952399148e-05]
2023-05-09 13:46:51,329 :: INFO :: Recall [5.458813253998581e-05, 0.00010917626507997162, 0.0003275287952399148]
2023-05-09 13:46:51,329 :: INFO :: ndcg [5.458813253998581e-05, 7.99900801919699e-05, 0.0001525794239754394]
2023-05-09 13:46:57,236 :: INFO :: Epoch 170: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0, MLP.norm 0.001959695480763912
2023-05-09 13:47:50,566 :: INFO :: ----- val -----
2023-05-09 13:47:50,566 :: INFO :: Precision [0.0, 0.0, 8.851515822084533e-06]
2023-05-09 13:47:50,566 :: INFO :: Recall [0.0, 0.0, 8.851515822084532e-05]
2023-05-09 13:47:50,566 :: INFO :: ndcg [0.0, 0.0, 2.9087726610843255e-05]
2023-05-09 13:48:45,128 :: INFO :: ----- test -----
2023-05-09 13:48:45,128 :: INFO :: Precision [0.0, 0.0, 8.188219880997872e-06]
2023-05-09 13:48:45,128 :: INFO :: Recall [0.0, 0.0, 8.18821988099787e-05]
2023-05-09 13:48:45,128 :: INFO :: ndcg [0.0, 0.0, 2.399584170259722e-05]
2023-05-09 13:48:50,972 :: INFO :: Epoch 175: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0, MLP.norm 0.0020478025544434786
2023-05-09 13:49:44,128 :: INFO :: ----- val -----
2023-05-09 13:49:44,144 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 13:49:44,144 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 13:49:44,144 :: INFO :: ndcg [0.0, 0.0, 1.4752526370140887e-05]
2023-05-09 13:50:37,550 :: INFO :: ----- test -----
2023-05-09 13:50:37,550 :: INFO :: Precision [0.0, 0.0, 5.458813253998581e-06]
2023-05-09 13:50:37,550 :: INFO :: Recall [0.0, 0.0, 5.458813253998581e-05]
2023-05-09 13:50:37,550 :: INFO :: ndcg [0.0, 0.0, 1.9169105410237195e-05]
2023-05-09 13:50:43,316 :: INFO :: Epoch 180: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0, MLP.norm 0.0018744878470897675
2023-05-09 13:51:37,441 :: INFO :: ----- val -----
2023-05-09 13:51:37,441 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 13:51:37,441 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 13:51:37,441 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 13:52:32,222 :: INFO :: ----- test -----
2023-05-09 13:52:32,222 :: INFO :: Precision [0.0, 5.458813253998581e-06, 5.458813253998581e-06]
2023-05-09 13:52:32,222 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 5.458813253998581e-05]
2023-05-09 13:52:32,222 :: INFO :: ndcg [0.0, 1.7220638505689654e-05, 2.6942981076463772e-05]
2023-05-09 13:52:38,035 :: INFO :: Epoch 185: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0, MLP.norm 0.0020866640843451023
2023-05-09 13:53:31,175 :: INFO :: ----- val -----
2023-05-09 13:53:31,175 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 13:53:31,175 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 13:53:31,175 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 13:54:23,847 :: INFO :: ----- test -----
2023-05-09 13:54:23,847 :: INFO :: Precision [0.0, 5.458813253998581e-06, 1.0917626507997163e-05]
2023-05-09 13:54:23,847 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 0.00010917626507997162]
2023-05-09 13:54:23,847 :: INFO :: ndcg [0.0, 1.3647033134996452e-05, 3.996569373068374e-05]
2023-05-09 13:54:29,456 :: INFO :: Epoch 190: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0, MLP.norm 0.001873630448244512
2023-05-09 13:55:23,956 :: INFO :: ----- val -----
2023-05-09 13:55:23,972 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 13:55:23,972 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 13:55:23,972 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 13:56:19,316 :: INFO :: ----- test -----
2023-05-09 13:56:19,316 :: INFO :: Precision [0.0, 1.0917626507997163e-05, 1.0917626507997163e-05]
2023-05-09 13:56:19,316 :: INFO :: Recall [0.0, 5.458813253998581e-05, 0.00010917626507997162]
2023-05-09 13:56:19,316 :: INFO :: ndcg [0.0, 2.231370067438001e-05, 4.002204201722247e-05]
2023-05-09 13:56:25,206 :: INFO :: Epoch 195: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0, MLP.norm 0.001954291481524706
2023-05-09 13:57:18,800 :: INFO :: ----- val -----
2023-05-09 13:57:18,800 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 13:57:18,800 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 13:57:18,800 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 13:58:12,725 :: INFO :: ----- test -----
2023-05-09 13:58:12,725 :: INFO :: Precision [0.0, 0.0, 8.188219880997872e-06]
2023-05-09 13:58:12,725 :: INFO :: Recall [0.0, 0.0, 8.18821988099787e-05]
2023-05-09 13:58:12,725 :: INFO :: ndcg [0.0, 0.0, 2.4322419827661183e-05]
2023-05-09 13:58:18,491 :: INFO :: Epoch 200: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0, MLP.norm 0.002102443715557456
2023-05-09 13:59:13,522 :: INFO :: ----- val -----
2023-05-09 13:59:13,522 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 13:59:13,522 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 13:59:13,522 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 14:00:06,616 :: INFO :: ----- test -----
2023-05-09 14:00:06,616 :: INFO :: Precision [0.0, 5.458813253998581e-06, 1.3647033134996452e-05]
2023-05-09 14:00:06,616 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 0.00013647033134996453]
2023-05-09 14:00:06,616 :: INFO :: ndcg [0.0, 1.1754914516987637e-05, 4.828362052060185e-05]
2023-05-09 14:00:12,319 :: INFO :: Epoch 205: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0, MLP.norm 0.0021281905937939882
2023-05-09 14:01:04,025 :: INFO :: ----- val -----
2023-05-09 14:01:04,025 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 14:01:04,025 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 14:01:04,025 :: INFO :: ndcg [0.0, 0.0, 1.4752526370140887e-05]
2023-05-09 14:01:57,494 :: INFO :: ----- test -----
2023-05-09 14:01:57,494 :: INFO :: Precision [0.0, 5.458813253998581e-06, 5.458813253998581e-06]
2023-05-09 14:01:57,494 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 5.458813253998581e-05]
2023-05-09 14:01:57,494 :: INFO :: ndcg [0.0, 1.1754914516987637e-05, 1.9644669042832058e-05]
2023-05-09 14:02:03,369 :: INFO :: Epoch 210: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0, MLP.norm 0.002356016542762518
2023-05-09 14:03:00,275 :: INFO :: ----- val -----
2023-05-09 14:03:00,275 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 14:03:00,275 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 14:03:00,291 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 14:03:54,434 :: INFO :: ----- test -----
2023-05-09 14:03:54,434 :: INFO :: Precision [0.0, 5.458813253998581e-06, 1.910584638899503e-05]
2023-05-09 14:03:54,434 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 0.00019105846388995032]
2023-05-09 14:03:54,434 :: INFO :: ndcg [0.0, 1.1754914516987637e-05, 5.943215900167607e-05]
2023-05-09 14:04:00,199 :: INFO :: Epoch 215: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0, MLP.norm 0.002370045520365238
2023-05-09 14:04:54,903 :: INFO :: ----- val -----
2023-05-09 14:04:54,903 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 14:04:54,903 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 14:04:54,903 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 14:05:49,668 :: INFO :: ----- test -----
2023-05-09 14:05:49,668 :: INFO :: Precision [0.0, 5.458813253998581e-06, 1.3647033134996452e-05]
2023-05-09 14:05:49,668 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 0.00013647033134996453]
2023-05-09 14:05:49,668 :: INFO :: ndcg [0.0, 1.0558786157392369e-05, 4.581181611998088e-05]
2023-05-09 14:05:55,324 :: INFO :: Epoch 220: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0, MLP.norm 0.0022792594972997904
2023-05-09 14:06:50,871 :: INFO :: ----- val -----
2023-05-09 14:06:50,871 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 14:06:50,871 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 14:06:50,871 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 14:07:45,543 :: INFO :: ----- test -----
2023-05-09 14:07:45,543 :: INFO :: Precision [2.7294066269992904e-05, 1.0917626507997163e-05, 1.910584638899503e-05]
2023-05-09 14:07:45,543 :: INFO :: Recall [2.7294066269992904e-05, 5.458813253998581e-05, 0.00019105846388995032]
2023-05-09 14:07:45,543 :: INFO :: ndcg [2.7294066269992904e-05, 5.458813253998581e-05, 8.888791945267019e-05]
2023-05-09 14:07:51,293 :: INFO :: Epoch 225: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 4.6362226100329836e-20, MLP.norm 0.002370502334088087
2023-05-09 14:08:48,090 :: INFO :: ----- val -----
2023-05-09 14:08:48,090 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 14:08:48,090 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 14:08:48,090 :: INFO :: ndcg [0.0, 0.0, 1.2793309418804509e-05]
2023-05-09 14:09:42,968 :: INFO :: ----- test -----
2023-05-09 14:09:42,968 :: INFO :: Precision [0.0, 0.0, 5.458813253998581e-06]
2023-05-09 14:09:42,968 :: INFO :: Recall [0.0, 0.0, 5.458813253998581e-05]
2023-05-09 14:09:42,968 :: INFO :: ndcg [0.0, 0.0, 1.61060871767528e-05]
2023-05-09 14:09:48,749 :: INFO :: Epoch 230: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 1.0001335697118474e-11, MLP.norm 0.0023682070896029472
2023-05-09 14:10:45,593 :: INFO :: ----- val -----
2023-05-09 14:10:45,593 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 14:10:45,593 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 14:10:45,593 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 14:11:40,955 :: INFO :: ----- test -----
2023-05-09 14:11:40,955 :: INFO :: Precision [0.0, 0.0, 5.458813253998581e-06]
2023-05-09 14:11:40,955 :: INFO :: Recall [0.0, 0.0, 5.458813253998581e-05]
2023-05-09 14:11:40,955 :: INFO :: ndcg [0.0, 0.0, 1.6500073778689248e-05]
2023-05-09 14:11:46,830 :: INFO :: Epoch 235: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 1.9110630091745406e-06, MLP.norm 0.002698881784453988
2023-05-09 14:12:40,596 :: INFO :: ----- val -----
2023-05-09 14:12:40,596 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 14:12:40,596 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 14:12:40,596 :: INFO :: ndcg [0.0, 0.0, 1.4752526370140887e-05]
2023-05-09 14:13:35,148 :: INFO :: ----- test -----
2023-05-09 14:13:35,148 :: INFO :: Precision [0.0, 5.458813253998581e-06, 1.3647033134996452e-05]
2023-05-09 14:13:35,148 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 0.00012282329821496806]
2023-05-09 14:13:35,148 :: INFO :: ndcg [0.0, 1.3647033134996452e-05, 4.6414318802527346e-05]
2023-05-09 14:13:41,117 :: INFO :: Epoch 240: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 1.3046620450651858e-09, MLP.norm 0.002717302879318595
2023-05-09 14:14:37,742 :: INFO :: ----- val -----
2023-05-09 14:14:37,742 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 14:14:37,742 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 14:14:37,742 :: INFO :: ndcg [0.0, 0.0, 1.3961711740904128e-05]
2023-05-09 14:15:33,304 :: INFO :: ----- test -----
2023-05-09 14:15:33,304 :: INFO :: Precision [0.0, 5.458813253998581e-06, 8.188219880997872e-06]
2023-05-09 14:15:33,304 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 8.18821988099787e-05]
2023-05-09 14:15:33,304 :: INFO :: ndcg [0.0, 1.7220638505689654e-05, 3.5995757313990405e-05]
2023-05-09 14:15:39,335 :: INFO :: Epoch 245: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 1.1357173207215965e-05, MLP.norm 0.0025642472319304943
2023-05-09 14:16:35,679 :: INFO :: ----- val -----
2023-05-09 14:16:35,679 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 14:16:35,679 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 14:16:35,679 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 14:17:33,007 :: INFO :: ----- test -----
2023-05-09 14:17:33,007 :: INFO :: Precision [0.0, 1.0917626507997163e-05, 1.0917626507997163e-05]
2023-05-09 14:17:33,007 :: INFO :: Recall [0.0, 5.458813253998581e-05, 0.00010917626507997162]
2023-05-09 14:17:33,007 :: INFO :: ndcg [0.0, 2.5401947651984092e-05, 4.3734609475603034e-05]
2023-05-09 14:17:38,976 :: INFO :: Epoch 250: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 4.1096550376096275e-06, MLP.norm 0.0026513184420764446
2023-05-09 14:18:36,382 :: INFO :: ----- val -----
2023-05-09 14:18:36,382 :: INFO :: Precision [0.0, 0.0, 8.851515822084533e-06]
2023-05-09 14:18:36,382 :: INFO :: Recall [0.0, 0.0, 8.851515822084532e-05]
2023-05-09 14:18:36,382 :: INFO :: ndcg [0.0, 0.0, 2.611616826651335e-05]
2023-05-09 14:19:32,273 :: INFO :: ----- test -----
2023-05-09 14:19:32,273 :: INFO :: Precision [0.0, 5.458813253998581e-06, 1.0917626507997163e-05]
2023-05-09 14:19:32,273 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 0.00010917626507997162]
2023-05-09 14:19:32,273 :: INFO :: ndcg [0.0, 1.0558786157392369e-05, 3.847717290816175e-05]
2023-05-09 14:19:38,069 :: INFO :: Epoch 255: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 1.639742731640581e-05, MLP.norm 0.0025122377555817366
2023-05-09 14:20:34,492 :: INFO :: ----- val -----
2023-05-09 14:20:34,492 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 14:20:34,492 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 14:20:34,492 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 14:21:30,648 :: INFO :: ----- test -----
2023-05-09 14:21:30,648 :: INFO :: Precision [0.0, 0.0, 8.188219880997872e-06]
2023-05-09 14:21:30,648 :: INFO :: Recall [0.0, 0.0, 8.18821988099787e-05]
2023-05-09 14:21:30,648 :: INFO :: ndcg [0.0, 0.0, 2.582842974752692e-05]
2023-05-09 14:21:36,601 :: INFO :: Epoch 260: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 1.3206288713263348e-05, MLP.norm 0.002689681714400649
2023-05-09 14:22:33,695 :: INFO :: ----- val -----
2023-05-09 14:22:33,695 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 14:22:33,695 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 14:22:33,695 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 14:23:28,257 :: INFO :: ----- test -----
2023-05-09 14:23:28,257 :: INFO :: Precision [0.0, 5.458813253998581e-06, 8.188219880997872e-06]
2023-05-09 14:23:28,257 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 6.823516567498226e-05]
2023-05-09 14:23:28,257 :: INFO :: ndcg [0.0, 1.1754914516987637e-05, 3.0147106913685697e-05]
2023-05-09 14:23:34,023 :: INFO :: Epoch 265: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 4.83527073811274e-05, MLP.norm 0.002746578538790345
2023-05-09 14:24:27,288 :: INFO :: ----- val -----
2023-05-09 14:24:27,288 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 14:24:27,288 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 14:24:27,288 :: INFO :: ndcg [0.0, 0.0, 1.3322858847708838e-05]
2023-05-09 14:25:23,742 :: INFO :: ----- test -----
2023-05-09 14:25:23,742 :: INFO :: Precision [0.0, 0.0, 2.7294066269992907e-06]
2023-05-09 14:25:23,742 :: INFO :: Recall [0.0, 0.0, 2.7294066269992904e-05]
2023-05-09 14:25:23,742 :: INFO :: ndcg [0.0, 0.0, 8.21633265090838e-06]
2023-05-09 14:25:29,554 :: INFO :: Epoch 270: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 4.501564762904309e-05, MLP.norm 0.0026715854182839394
2023-05-09 14:26:26,992 :: INFO :: ----- val -----
2023-05-09 14:26:26,992 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 14:26:26,992 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 14:26:26,992 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 14:27:25,429 :: INFO :: ----- test -----
2023-05-09 14:27:25,429 :: INFO :: Precision [0.0, 0.0, 1.0917626507997163e-05]
2023-05-09 14:27:25,429 :: INFO :: Recall [0.0, 0.0, 0.00010917626507997162]
2023-05-09 14:27:25,429 :: INFO :: ndcg [0.0, 0.0, 3.4208415121531715e-05]
2023-05-09 14:27:31,444 :: INFO :: Epoch 275: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 4.716950570582412e-05, MLP.norm 0.0030431768391281366
2023-05-09 14:28:28,804 :: INFO :: ----- val -----
2023-05-09 14:28:28,804 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 14:28:28,804 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 14:28:28,804 :: INFO :: ndcg [0.0, 0.0, 1.3961711740904128e-05]
2023-05-09 14:29:27,179 :: INFO :: ----- test -----
2023-05-09 14:29:27,179 :: INFO :: Precision [0.0, 0.0, 5.458813253998581e-06]
2023-05-09 14:29:27,179 :: INFO :: Recall [0.0, 0.0, 5.458813253998581e-05]
2023-05-09 14:29:27,179 :: INFO :: ndcg [0.0, 0.0, 1.7708341342842464e-05]
2023-05-09 14:29:33,211 :: INFO :: Epoch 280: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 4.874914884567261e-05, MLP.norm 0.002980073681101203
2023-05-09 14:30:29,773 :: INFO :: ----- val -----
2023-05-09 14:30:29,773 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 14:30:29,773 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 14:30:29,773 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 14:31:27,867 :: INFO :: ----- test -----
2023-05-09 14:31:27,867 :: INFO :: Precision [0.0, 1.0917626507997163e-05, 8.188219880997872e-06]
2023-05-09 14:31:27,867 :: INFO :: Recall [0.0, 5.458813253998581e-05, 8.18821988099787e-05]
2023-05-09 14:31:27,867 :: INFO :: ndcg [0.0, 2.8975553022677294e-05, 3.7585872275522124e-05]
2023-05-09 14:31:33,773 :: INFO :: Epoch 285: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0002696090959943831, MLP.norm 0.0028922739438712597
2023-05-09 14:32:31,866 :: INFO :: ----- val -----
2023-05-09 14:32:31,866 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 14:32:31,866 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 14:32:31,866 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 14:33:30,367 :: INFO :: ----- test -----
2023-05-09 14:33:30,367 :: INFO :: Precision [0.0, 0.0, 1.3647033134996452e-05]
2023-05-09 14:33:30,367 :: INFO :: Recall [0.0, 0.0, 0.00012282329821496806]
2023-05-09 14:33:30,367 :: INFO :: ndcg [0.0, 0.0, 4.2191885882592485e-05]
2023-05-09 14:33:36,273 :: INFO :: Epoch 290: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.00023252741084434092, MLP.norm 0.0027972508687525988
2023-05-09 14:34:34,085 :: INFO :: ----- val -----
2023-05-09 14:34:34,085 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 14:34:34,085 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 14:34:34,085 :: INFO :: ndcg [0.0, 0.0, 1.2793309418804509e-05]
2023-05-09 14:35:32,648 :: INFO :: ----- test -----
2023-05-09 14:35:32,648 :: INFO :: Precision [0.0, 1.0917626507997163e-05, 8.188219880997872e-06]
2023-05-09 14:35:32,648 :: INFO :: Recall [0.0, 5.458813253998581e-05, 8.18821988099787e-05]
2023-05-09 14:35:32,648 :: INFO :: ndcg [0.0, 2.5401947651984092e-05, 3.329170217782851e-05]
2023-05-09 14:35:38,523 :: INFO :: Epoch 295: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.00022146580158732831, MLP.norm 0.003257307456806302
2023-05-09 14:36:35,367 :: INFO :: ----- val -----
2023-05-09 14:36:35,367 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 14:36:35,367 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 14:36:35,367 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 14:37:32,320 :: INFO :: ----- test -----
2023-05-09 14:37:32,320 :: INFO :: Precision [0.0, 0.0, 8.188219880997872e-06]
2023-05-09 14:37:32,320 :: INFO :: Recall [0.0, 0.0, 6.823516567498226e-05]
2023-05-09 14:37:32,320 :: INFO :: ndcg [0.0, 0.0, 2.5204109266750434e-05]
2023-05-09 14:37:38,086 :: INFO :: Epoch 300: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0001995335624087602, MLP.norm 0.0031524167861789465
2023-05-09 14:38:36,992 :: INFO :: ----- val -----
2023-05-09 14:38:36,992 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 14:38:36,992 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 14:38:36,992 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 14:39:34,429 :: INFO :: ----- test -----
2023-05-09 14:39:34,429 :: INFO :: Precision [0.0, 0.0, 2.7294066269992907e-06]
2023-05-09 14:39:34,429 :: INFO :: Recall [0.0, 0.0, 2.7294066269992904e-05]
2023-05-09 14:39:34,429 :: INFO :: ndcg [0.0, 0.0, 9.098022089997634e-06]
2023-05-09 14:39:40,257 :: INFO :: Epoch 305: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0001882243959698826, MLP.norm 0.003152557648718357
2023-05-09 14:40:36,382 :: INFO :: ----- val -----
2023-05-09 14:40:36,382 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 14:40:36,382 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 14:40:36,382 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 14:41:32,711 :: INFO :: ----- test -----
2023-05-09 14:41:32,711 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 14:41:32,711 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 14:41:32,711 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 14:41:38,523 :: INFO :: Epoch 310: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.00021251854195725173, MLP.norm 0.00324290432035923
2023-05-09 14:42:35,101 :: INFO :: ----- val -----
2023-05-09 14:42:35,101 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 14:42:35,101 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 14:42:35,101 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 14:43:33,179 :: INFO :: ----- test -----
2023-05-09 14:43:33,179 :: INFO :: Precision [0.0, 0.0, 5.458813253998581e-06]
2023-05-09 14:43:33,179 :: INFO :: Recall [0.0, 0.0, 5.458813253998581e-05]
2023-05-09 14:43:33,179 :: INFO :: ndcg [0.0, 0.0, 1.8196044179995267e-05]
2023-05-09 14:43:39,117 :: INFO :: Epoch 315: loss tensor(1.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0002257401356473565, MLP.norm 0.0031606138218194246
2023-05-09 14:44:35,476 :: INFO :: ----- val -----
2023-05-09 14:44:35,476 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 14:44:35,476 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 14:44:35,476 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 14:45:33,163 :: INFO :: ----- test -----
2023-05-09 14:45:33,163 :: INFO :: Precision [0.0, 5.458813253998581e-06, 1.0917626507997163e-05]
2023-05-09 14:45:33,163 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 0.00010917626507997162]
2023-05-09 14:45:33,163 :: INFO :: ndcg [0.0, 1.0558786157392369e-05, 3.615688202607925e-05]
2023-05-09 14:45:33,163 :: INFO :: Epoch 315:
2023-05-09 14:46:27,632 :: INFO :: ----- val -----
2023-05-09 14:46:27,632 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 14:46:27,632 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 14:46:27,632 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 14:47:20,523 :: INFO :: ----- test -----
2023-05-09 14:47:20,523 :: INFO :: Precision [0.0, 5.458813253998581e-06, 1.0917626507997163e-05]
2023-05-09 14:47:20,523 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 0.00010917626507997162]
2023-05-09 14:47:20,523 :: INFO :: ndcg [0.0, 1.0558786157392369e-05, 3.615688202607925e-05]
2023-05-09 14:47:20,523 :: INFO :: final:
2023-05-09 14:47:20,523 :: INFO :: ----- test -----
2023-05-09 14:47:20,523 :: INFO :: Precision [0.0, 5.458813253998581e-06, 5.458813253998581e-06]
2023-05-09 14:47:20,523 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 5.458813253998581e-05]
2023-05-09 14:47:20,523 :: INFO :: ndcg [0.0, 1.0558786157392369e-05, 1.844854068323679e-05]
2023-05-09 14:47:20,523 :: INFO :: max_epoch 105:
2023-05-09 15:32:20,150 :: INFO :: log info to logs/tiktok_Attention.log
2023-05-09 15:32:20,150 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=256, dataset='tiktok', device='cuda:0', epoch=5, f_epoch=20, f_max=10, feat_dim=32, ite=5, lam=0.1, lr=0.001, model='Attention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=0, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=128, tolog=1, wdi=2)
2023-05-09 15:32:21,947 :: INFO :: torch.Size([76083, 384])
2023-05-09 15:32:51,338 :: INFO :: ERM mask: from pre-train tensor([0.5523, 0.5259, 0.5222, 0.5572, 0.5327, 0.5070, 0.5500, 0.5492, 0.5193,
        0.5253, 0.5332, 0.4896, 0.5381, 0.5486, 0.5384, 0.5155, 0.5169, 0.5520,
        0.5182, 0.5483, 0.5210, 0.5311, 0.5536, 0.5246, 0.5053, 0.5231, 0.5224,
        0.5452, 0.5878, 0.5132, 0.5371, 0.5449, 0.5574, 0.5425, 0.4957, 0.4715,
        0.5335, 0.5379, 0.5006, 0.5452, 0.4860, 0.5240, 0.5384, 0.5114, 0.5147,
        0.5179, 0.5337, 0.5109, 0.5339, 0.5208, 0.5157, 0.5156, 0.5030, 0.5171,
        0.5412, 0.5667, 0.5418, 0.5779, 0.5301, 0.5018, 0.5237, 0.5331, 0.5018,
        0.5221, 0.5412, 0.5186, 0.5697, 0.5200, 0.5374, 0.4886, 0.5462, 0.5385,
        0.5334, 0.5632, 0.5535, 0.5001, 0.5610, 0.5176, 0.5444, 0.5573, 0.5491,
        0.5457, 0.5399, 0.5795, 0.4930, 0.5522, 0.5268, 0.5256, 0.5224, 0.4933,
        0.5170, 0.5647, 0.5282, 0.5471, 0.5299, 0.5576, 0.5260, 0.5116, 0.5053,
        0.5105, 0.5310, 0.5316, 0.5313, 0.5211, 0.5433, 0.4741, 0.5302, 0.4994,
        0.5328, 0.5490, 0.5356, 0.5382, 0.5416, 0.5427, 0.4899, 0.4788, 0.5292,
        0.5111, 0.5119, 0.5341, 0.5110, 0.5220, 0.5238, 0.5114, 0.5268, 0.5035,
        0.5178, 0.5598, 0.6188, 0.6112, 0.6297, 0.5914, 0.5822, 0.6098, 0.5972,
        0.5793, 0.5546, 0.5439, 0.5836, 0.5087, 0.6384, 0.5124, 0.6331, 0.6191,
        0.6379, 0.6253, 0.5755, 0.6454, 0.6367, 0.6163, 0.5238, 0.6290, 0.6323,
        0.4405, 0.5312, 0.5224, 0.5356, 0.4422, 0.5724, 0.4324, 0.6181, 0.4321,
        0.6054, 0.5531, 0.5971, 0.5355, 0.4743, 0.5560, 0.5408, 0.6033, 0.6434,
        0.5992, 0.4383, 0.6331, 0.6397, 0.5495, 0.5566, 0.6159, 0.5573, 0.5036,
        0.6179, 0.5539, 0.5696, 0.4443, 0.6122, 0.6447, 0.4550, 0.6233, 0.6560,
        0.4388, 0.4753, 0.5810, 0.6089, 0.4624, 0.5718, 0.6314, 0.6283, 0.5277,
        0.6181, 0.6399, 0.6389, 0.6474, 0.5974, 0.5941, 0.6270, 0.6447, 0.5028,
        0.4349, 0.5705, 0.5839, 0.6426, 0.6031, 0.5620, 0.5096, 0.6088, 0.6536,
        0.6060, 0.4722, 0.6198, 0.4432, 0.6411, 0.5622, 0.6283, 0.6331, 0.5882,
        0.6428, 0.6067, 0.6445, 0.5770, 0.6447, 0.6117, 0.5690, 0.5810, 0.5622,
        0.6089, 0.6416, 0.5664, 0.5543, 0.5334, 0.6065, 0.6115, 0.6256, 0.6344,
        0.6195, 0.5579, 0.6275, 0.4503, 0.6084, 0.5772, 0.5515, 0.5226, 0.6330,
        0.6331, 0.6493, 0.4748, 0.6175, 0.6572, 0.5928, 0.6355, 0.6349, 0.6353,
        0.6695, 0.6037, 0.6250, 0.5876, 0.6446, 0.6170, 0.5594, 0.6146, 0.6268,
        0.5421, 0.6314, 0.5941, 0.5577, 0.6264, 0.5975, 0.6488, 0.6527, 0.5910,
        0.6111, 0.6245, 0.6489, 0.6085, 0.6041, 0.6553, 0.6085, 0.6204, 0.6403,
        0.5950, 0.6281, 0.6303, 0.6395, 0.6359, 0.6108, 0.5381, 0.6115, 0.6221,
        0.5269, 0.6162, 0.6224, 0.5490, 0.6288, 0.6160, 0.5294, 0.6583, 0.5966,
        0.6049, 0.5663, 0.6351, 0.6151, 0.5785, 0.6551, 0.6571, 0.6495, 0.6082,
        0.6212, 0.6220, 0.6025, 0.6219, 0.5652, 0.6332, 0.5718, 0.6434, 0.5699,
        0.6529, 0.5734, 0.6102, 0.6301, 0.5981, 0.6002, 0.6296, 0.5708, 0.6193,
        0.6039, 0.6597, 0.6034, 0.5672, 0.6290, 0.6162, 0.5913, 0.6254, 0.6155,
        0.6071, 0.6643, 0.6338, 0.6073, 0.5505, 0.5813, 0.5580, 0.6123, 0.6094,
        0.5500, 0.6313, 0.5396, 0.6448, 0.5937, 0.5418, 0.6394, 0.5797, 0.6368,
        0.6088, 0.5735, 0.6118, 0.6520, 0.6552, 0.6271, 0.6436, 0.5578, 0.5755,
        0.6347, 0.6170, 0.6345, 0.6267, 0.6242, 0.6599, 0.6558, 0.6137, 0.6050,
        0.6174, 0.5227, 0.6234, 0.6302, 0.6345, 0.6083], dtype=torch.float64)
2023-05-09 15:36:02,913 :: INFO :: Epoch 5: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0027210963889956474, MLP.norm 0.00298096751794219
2023-05-09 15:36:55,678 :: INFO :: ----- val -----
2023-05-09 15:36:55,678 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 15:36:55,678 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 15:36:55,678 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 15:37:48,384 :: INFO :: ----- test -----
2023-05-09 15:37:48,399 :: INFO :: Precision [0.0, 1.0917626507997163e-05, 1.3647033134996452e-05]
2023-05-09 15:37:48,399 :: INFO :: Recall [0.0, 5.458813253998581e-05, 0.00013647033134996453]
2023-05-09 15:37:48,399 :: INFO :: ndcg [0.0, 2.5401947651984092e-05, 5.162436400144745e-05]
2023-05-09 15:40:13,540 :: INFO :: Epoch 10: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029346789233386517, MLP.norm 0.0032015368342399597
2023-05-09 15:41:08,337 :: INFO :: ----- val -----
2023-05-09 15:41:08,337 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 15:41:08,337 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 15:41:08,337 :: INFO :: ndcg [0.0, 0.0, 1.4752526370140887e-05]
2023-05-09 15:42:03,696 :: INFO :: ----- test -----
2023-05-09 15:42:03,696 :: INFO :: Precision [0.0, 1.0917626507997163e-05, 8.188219880997872e-06]
2023-05-09 15:42:03,696 :: INFO :: Recall [0.0, 5.458813253998581e-05, 8.18821988099787e-05]
2023-05-09 15:42:03,696 :: INFO :: ndcg [0.0, 2.231370067438001e-05, 3.092401992722483e-05]
2023-05-09 15:44:31,712 :: INFO :: Epoch 15: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0028776649851351976, MLP.norm 0.003110026940703392
2023-05-09 15:45:26,024 :: INFO :: ----- val -----
2023-05-09 15:45:26,024 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 15:45:26,024 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 15:45:26,024 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 15:46:19,993 :: INFO :: ----- test -----
2023-05-09 15:46:19,993 :: INFO :: Precision [0.0, 0.0, 5.458813253998581e-06]
2023-05-09 15:46:19,993 :: INFO :: Recall [0.0, 0.0, 5.458813253998581e-05]
2023-05-09 15:46:19,993 :: INFO :: ndcg [0.0, 0.0, 1.6826651903753206e-05]
2023-05-09 15:48:50,039 :: INFO :: Epoch 20: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.002921166131272912, MLP.norm 0.0031855632551014423
2023-05-09 15:49:43,112 :: INFO :: ----- val -----
2023-05-09 15:49:43,112 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 15:49:43,112 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 15:49:43,112 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 15:50:35,532 :: INFO :: ----- test -----
2023-05-09 15:50:35,532 :: INFO :: Precision [0.0, 0.0, 5.458813253998581e-06]
2023-05-09 15:50:35,532 :: INFO :: Recall [0.0, 0.0, 5.458813253998581e-05]
2023-05-09 15:50:35,532 :: INFO :: ndcg [0.0, 0.0, 1.7314354740906013e-05]
2023-05-09 15:53:00,860 :: INFO :: Epoch 25: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.002899465849623084, MLP.norm 0.003190056188032031
2023-05-09 15:53:53,921 :: INFO :: ----- val -----
2023-05-09 15:53:53,921 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 15:53:53,921 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 15:53:53,921 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 15:54:47,170 :: INFO :: ----- test -----
2023-05-09 15:54:47,170 :: INFO :: Precision [0.0, 5.458813253998581e-06, 5.458813253998581e-06]
2023-05-09 15:54:47,170 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 5.458813253998581e-05]
2023-05-09 15:54:47,170 :: INFO :: ndcg [0.0, 1.0558786157392369e-05, 1.877511880830075e-05]
2023-05-09 15:57:12,740 :: INFO :: Epoch 30: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.002917045494541526, MLP.norm 0.0031886789947748184
2023-05-09 15:58:08,175 :: INFO :: ----- val -----
2023-05-09 15:58:08,175 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 15:58:08,175 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 15:58:08,175 :: INFO :: ndcg [0.0, 0.0, 1.2793309418804509e-05]
2023-05-09 15:59:03,502 :: INFO :: ----- test -----
2023-05-09 15:59:03,502 :: INFO :: Precision [0.0, 0.0, 8.188219880997872e-06]
2023-05-09 15:59:03,502 :: INFO :: Recall [0.0, 0.0, 8.18821988099787e-05]
2023-05-09 15:59:03,502 :: INFO :: ndcg [0.0, 0.0, 2.916702771232236e-05]
2023-05-09 16:01:34,107 :: INFO :: Epoch 35: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029201656579971313, MLP.norm 0.0032327251974493265
2023-05-09 16:02:29,137 :: INFO :: ----- val -----
2023-05-09 16:02:29,137 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 16:02:29,137 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 16:02:29,137 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 16:03:24,636 :: INFO :: ----- test -----
2023-05-09 16:03:24,636 :: INFO :: Precision [0.0, 5.458813253998581e-06, 1.3647033134996452e-05]
2023-05-09 16:03:24,636 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 0.00013647033134996453]
2023-05-09 16:03:24,636 :: INFO :: ndcg [0.0, 1.3647033134996452e-05, 4.6579772215502455e-05]
2023-05-09 16:05:54,696 :: INFO :: Epoch 40: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.002896955469623208, MLP.norm 0.0030486960895359516
2023-05-09 16:06:50,616 :: INFO :: ----- val -----
2023-05-09 16:06:50,616 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 16:06:50,616 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 16:06:50,616 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 16:07:46,990 :: INFO :: ----- test -----
2023-05-09 16:07:46,990 :: INFO :: Precision [0.0, 5.458813253998581e-06, 1.3647033134996452e-05]
2023-05-09 16:07:46,990 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 0.00013647033134996453]
2023-05-09 16:07:46,990 :: INFO :: ndcg [0.0, 1.1754914516987637e-05, 5.1170846826431894e-05]
2023-05-09 16:10:18,643 :: INFO :: Epoch 45: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029177952092140913, MLP.norm 0.0031242447439581156
2023-05-09 16:11:13,939 :: INFO :: ----- val -----
2023-05-09 16:11:13,939 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 16:11:13,939 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 16:11:13,939 :: INFO :: ndcg [0.0, 0.0, 1.5764867763134417e-05]
2023-05-09 16:12:09,616 :: INFO :: ----- test -----
2023-05-09 16:12:09,616 :: INFO :: Precision [0.0, 1.0917626507997163e-05, 8.188219880997872e-06]
2023-05-09 16:12:09,616 :: INFO :: Recall [0.0, 5.458813253998581e-05, 8.18821988099787e-05]
2023-05-09 16:12:09,616 :: INFO :: ndcg [0.0, 2.3509829033975273e-05, 3.053003332528839e-05]
2023-05-09 16:14:37,629 :: INFO :: Epoch 50: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.002895629033446312, MLP.norm 0.0031468027736991644
2023-05-09 16:15:31,831 :: INFO :: ----- val -----
2023-05-09 16:15:31,831 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 16:15:31,831 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 16:15:31,831 :: INFO :: ndcg [0.0, 0.0, 1.3322858847708838e-05]
2023-05-09 16:16:24,302 :: INFO :: ----- test -----
2023-05-09 16:16:24,317 :: INFO :: Precision [0.0, 5.458813253998581e-06, 1.0917626507997163e-05]
2023-05-09 16:16:24,317 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 0.00010917626507997162]
2023-05-09 16:16:24,317 :: INFO :: ndcg [0.0, 1.1754914516987637e-05, 3.72567661394506e-05]
2023-05-09 16:18:50,522 :: INFO :: Epoch 55: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029175118543207645, MLP.norm 0.0030948761850595474
2023-05-09 16:19:44,475 :: INFO :: ----- val -----
2023-05-09 16:19:44,475 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 16:19:44,475 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 16:19:44,475 :: INFO :: ndcg [0.0, 0.0, 1.5764867763134417e-05]
2023-05-09 16:20:40,818 :: INFO :: ----- test -----
2023-05-09 16:20:40,818 :: INFO :: Precision [0.0, 0.0, 5.458813253998581e-06]
2023-05-09 16:20:40,818 :: INFO :: Recall [0.0, 0.0, 5.458813253998581e-05]
2023-05-09 16:20:40,818 :: INFO :: ndcg [0.0, 0.0, 1.7314354740906013e-05]
2023-05-09 16:23:12,753 :: INFO :: Epoch 60: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029039792716503143, MLP.norm 0.0030603245832026005
2023-05-09 16:24:09,314 :: INFO :: ----- val -----
2023-05-09 16:24:09,314 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 16:24:09,314 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 16:24:09,314 :: INFO :: ndcg [0.0, 0.0, 1.3961711740904128e-05]
2023-05-09 16:25:05,361 :: INFO :: ----- test -----
2023-05-09 16:25:05,361 :: INFO :: Precision [0.0, 0.0, 1.910584638899503e-05]
2023-05-09 16:25:05,361 :: INFO :: Recall [0.0, 0.0, 0.00019105846388995032]
2023-05-09 16:25:05,361 :: INFO :: ndcg [0.0, 0.0, 6.0620791952435345e-05]
2023-05-09 16:27:32,688 :: INFO :: Epoch 65: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029171474743634462, MLP.norm 0.003110054414719343
2023-05-09 16:28:27,391 :: INFO :: ----- val -----
2023-05-09 16:28:27,391 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 16:28:27,391 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 16:28:27,391 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 16:29:22,109 :: INFO :: ----- test -----
2023-05-09 16:29:22,109 :: INFO :: Precision [0.0, 0.0, 2.7294066269992907e-06]
2023-05-09 16:29:22,109 :: INFO :: Recall [0.0, 0.0, 1.3647033134996452e-05]
2023-05-09 16:29:22,109 :: INFO :: ndcg [0.0, 0.0, 8.21633265090838e-06]
2023-05-09 17:05:33,192 :: INFO :: Epoch 70: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029092610348016024, MLP.norm 0.0029700754676014185
2023-05-09 17:06:32,567 :: INFO :: ----- val -----
2023-05-09 17:06:32,567 :: INFO :: Precision [0.0, 0.0, 8.851515822084533e-06]
2023-05-09 17:06:32,567 :: INFO :: Recall [0.0, 0.0, 8.851515822084532e-05]
2023-05-09 17:06:32,567 :: INFO :: ndcg [0.0, 0.0, 2.611616826651335e-05]
2023-05-09 17:07:33,988 :: INFO :: ----- test -----
2023-05-09 17:07:33,988 :: INFO :: Precision [0.0, 1.0917626507997163e-05, 1.0917626507997163e-05]
2023-05-09 17:07:33,988 :: INFO :: Recall [0.0, 5.458813253998581e-05, 0.00010917626507997162]
2023-05-09 17:07:33,988 :: INFO :: ndcg [0.0, 2.8975553022677294e-05, 4.301404474860263e-05]
2023-05-09 17:10:10,862 :: INFO :: Epoch 75: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029155132360756397, MLP.norm 0.0032005372922867537
2023-05-09 17:11:08,830 :: INFO :: ----- val -----
2023-05-09 17:11:08,830 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 17:11:08,830 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 17:11:08,830 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 17:12:05,580 :: INFO :: ----- test -----
2023-05-09 17:12:05,580 :: INFO :: Precision [2.7294066269992904e-05, 1.6376439761995743e-05, 1.0917626507997163e-05]
2023-05-09 17:12:05,580 :: INFO :: Recall [2.7294066269992904e-05, 8.18821988099787e-05, 0.00010917626507997162]
2023-05-09 17:12:05,580 :: INFO :: ndcg [2.7294066269992904e-05, 5.507349093307493e-05, 6.368381018591976e-05]
2023-05-09 17:14:38,485 :: INFO :: Epoch 80: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.002903413726016879, MLP.norm 0.0029833295848220587
2023-05-09 17:15:35,767 :: INFO :: ----- val -----
2023-05-09 17:15:35,767 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 17:15:35,767 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 17:15:35,767 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 17:16:34,922 :: INFO :: ----- test -----
2023-05-09 17:16:34,922 :: INFO :: Precision [0.0, 0.0, 2.7294066269992907e-06]
2023-05-09 17:16:34,922 :: INFO :: Recall [0.0, 0.0, 2.7294066269992904e-05]
2023-05-09 17:16:34,922 :: INFO :: ndcg [0.0, 0.0, 9.722342570774119e-06]
2023-05-09 17:19:12,125 :: INFO :: Epoch 85: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029082552064210176, MLP.norm 0.0031996900215744972
2023-05-09 17:20:10,390 :: INFO :: ----- val -----
2023-05-09 17:20:10,390 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 17:20:10,390 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 17:20:10,390 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 17:21:10,218 :: INFO :: ----- test -----
2023-05-09 17:21:10,218 :: INFO :: Precision [0.0, 0.0, 2.7294066269992907e-06]
2023-05-09 17:21:10,218 :: INFO :: Recall [0.0, 0.0, 2.7294066269992904e-05]
2023-05-09 17:21:10,218 :: INFO :: ndcg [0.0, 0.0, 8.610319252844827e-06]
2023-05-09 17:23:48,670 :: INFO :: Epoch 90: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.002904425375163555, MLP.norm 0.0033257792238146067
2023-05-09 17:24:48,201 :: INFO :: ----- val -----
2023-05-09 17:24:48,201 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 17:24:48,201 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 17:24:48,201 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 17:25:48,325 :: INFO :: ----- test -----
2023-05-09 17:25:48,325 :: INFO :: Precision [0.0, 5.458813253998581e-06, 5.458813253998581e-06]
2023-05-09 17:25:48,325 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 5.458813253998581e-05]
2023-05-09 17:25:48,325 :: INFO :: ndcg [0.0, 1.0558786157392369e-05, 2.1536787660840873e-05]
2023-05-09 17:28:26,824 :: INFO :: Epoch 95: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.002906804671511054, MLP.norm 0.0030187147203832865
2023-05-09 17:29:24,480 :: INFO :: ----- val -----
2023-05-09 17:29:24,480 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 17:29:24,480 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 17:29:24,480 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 17:30:24,121 :: INFO :: ----- test -----
2023-05-09 17:30:24,121 :: INFO :: Precision [0.0, 1.0917626507997163e-05, 1.3647033134996452e-05]
2023-05-09 17:30:24,121 :: INFO :: Recall [0.0, 5.458813253998581e-05, 0.00012282329821496806]
2023-05-09 17:30:24,121 :: INFO :: ndcg [0.0, 2.231370067438001e-05, 4.853611702384338e-05]
2023-05-09 17:32:59,605 :: INFO :: Epoch 100: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029218413401395082, MLP.norm 0.0029402533546090126
2023-05-09 17:33:59,652 :: INFO :: ----- val -----
2023-05-09 17:33:59,652 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 17:33:59,652 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 17:33:59,652 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 17:35:00,995 :: INFO :: ----- test -----
2023-05-09 17:35:00,995 :: INFO :: Precision [0.0, 5.458813253998581e-06, 1.0917626507997163e-05]
2023-05-09 17:35:00,995 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 0.00010917626507997162]
2023-05-09 17:35:00,995 :: INFO :: ndcg [0.0, 1.0558786157392369e-05, 3.664458486323206e-05]
2023-05-09 17:37:34,667 :: INFO :: Epoch 105: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029000467620790005, MLP.norm 0.0029039918445050716
2023-05-09 17:38:33,276 :: INFO :: ----- val -----
2023-05-09 17:38:33,276 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 17:38:33,276 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 17:38:33,276 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 17:39:32,026 :: INFO :: ----- test -----
2023-05-09 17:39:32,026 :: INFO :: Precision [0.0, 1.0917626507997163e-05, 1.0917626507997163e-05]
2023-05-09 17:39:32,026 :: INFO :: Recall [0.0, 5.458813253998581e-05, 0.00010917626507997162]
2023-05-09 17:39:32,026 :: INFO :: ndcg [0.0, 3.785285242738527e-05, 4.304906825321657e-05]
2023-05-09 17:42:09,322 :: INFO :: Epoch 110: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.002907706657424569, MLP.norm 0.0031971288844943047
2023-05-09 17:43:10,181 :: INFO :: ----- val -----
2023-05-09 17:43:10,181 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 17:43:10,181 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 17:43:10,181 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 17:44:11,353 :: INFO :: ----- test -----
2023-05-09 17:44:11,353 :: INFO :: Precision [0.0, 5.458813253998581e-06, 5.458813253998581e-06]
2023-05-09 17:44:11,353 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 5.458813253998581e-05]
2023-05-09 17:44:11,353 :: INFO :: ndcg [0.0, 1.1754914516987637e-05, 2.186336578590483e-05]
2023-05-09 17:46:48,728 :: INFO :: Epoch 115: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.002915868302807212, MLP.norm 0.003135786158964038
2023-05-09 17:47:47,478 :: INFO :: ----- val -----
2023-05-09 17:47:47,478 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 17:47:47,478 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 17:47:47,478 :: INFO :: ndcg [0.0, 0.0, 1.5764867763134417e-05]
2023-05-09 17:48:47,290 :: INFO :: ----- test -----
2023-05-09 17:48:47,290 :: INFO :: Precision [0.0, 1.0917626507997163e-05, 8.188219880997872e-06]
2023-05-09 17:48:47,290 :: INFO :: Recall [0.0, 5.458813253998581e-05, 8.18821988099787e-05]
2023-05-09 17:48:47,290 :: INFO :: ndcg [0.0, 2.231370067438001e-05, 3.092401992722483e-05]
2023-05-09 17:51:23,227 :: INFO :: Epoch 120: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029102370608597994, MLP.norm 0.0031773352529853582
2023-05-09 17:52:19,649 :: INFO :: ----- val -----
2023-05-09 17:52:19,649 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 17:52:19,649 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 17:52:19,649 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 17:53:18,914 :: INFO :: ----- test -----
2023-05-09 17:53:18,914 :: INFO :: Precision [2.7294066269992904e-05, 1.6376439761995743e-05, 2.1835253015994322e-05]
2023-05-09 17:53:18,914 :: INFO :: Recall [2.7294066269992904e-05, 8.18821988099787e-05, 0.00020470549702494677]
2023-05-09 17:53:18,914 :: INFO :: ndcg [2.7294066269992904e-05, 5.507349093307493e-05, 9.942454298566107e-05]
2023-05-09 17:55:53,211 :: INFO :: Epoch 125: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0028991380240768194, MLP.norm 0.0031811895314604044
2023-05-09 17:56:49,179 :: INFO :: ----- val -----
2023-05-09 17:56:49,179 :: INFO :: Precision [0.0, 0.0, 8.851515822084533e-06]
2023-05-09 17:56:49,179 :: INFO :: Recall [0.0, 0.0, 8.851515822084532e-05]
2023-05-09 17:56:49,179 :: INFO :: ndcg [0.0, 0.0, 2.972657950403855e-05]
2023-05-09 17:57:43,682 :: INFO :: ----- test -----
2023-05-09 17:57:43,682 :: INFO :: Precision [0.0, 0.0, 2.7294066269992907e-06]
2023-05-09 17:57:43,682 :: INFO :: Recall [0.0, 0.0, 2.7294066269992904e-05]
2023-05-09 17:57:43,682 :: INFO :: ndcg [0.0, 0.0, 8.21633265090838e-06]
2023-05-09 18:00:10,180 :: INFO :: Epoch 130: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029086514841765165, MLP.norm 0.0029984512366354465
2023-05-09 18:01:04,149 :: INFO :: ----- val -----
2023-05-09 18:01:04,149 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 18:01:04,149 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 18:01:04,149 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 18:01:59,398 :: INFO :: ----- test -----
2023-05-09 18:01:59,398 :: INFO :: Precision [0.0, 1.6376439761995743e-05, 1.0917626507997163e-05]
2023-05-09 18:01:59,398 :: INFO :: Recall [0.0, 8.18821988099787e-05, 0.00010917626507997162]
2023-05-09 18:01:59,398 :: INFO :: ndcg [0.0, 3.596073380937646e-05, 4.4177066460284833e-05]
2023-05-09 18:04:28,476 :: INFO :: Epoch 135: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029129504691809416, MLP.norm 0.0031759394332766533
2023-05-09 18:05:22,133 :: INFO :: ----- val -----
2023-05-09 18:05:22,133 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 18:05:22,133 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 18:05:22,133 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 18:06:16,885 :: INFO :: ----- test -----
2023-05-09 18:06:16,885 :: INFO :: Precision [0.0, 5.458813253998581e-06, 1.3647033134996452e-05]
2023-05-09 18:06:16,885 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 0.00013647033134996453]
2023-05-09 18:06:16,885 :: INFO :: ndcg [0.0, 1.7220638505689654e-05, 5.3749344509303866e-05]
2023-05-09 18:08:46,196 :: INFO :: Epoch 140: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029114950448274612, MLP.norm 0.003170598763972521
2023-05-09 18:09:41,914 :: INFO :: ----- val -----
2023-05-09 18:09:41,914 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 18:09:41,914 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 18:09:41,914 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 18:10:38,148 :: INFO :: ----- test -----
2023-05-09 18:10:38,148 :: INFO :: Precision [0.0, 0.0, 1.910584638899503e-05]
2023-05-09 18:10:38,148 :: INFO :: Recall [0.0, 0.0, 0.00019105846388995032]
2023-05-09 18:10:38,148 :: INFO :: ndcg [0.0, 0.0, 6.251826046322998e-05]
2023-05-09 18:13:07,289 :: INFO :: Epoch 145: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029161942657083273, MLP.norm 0.0031789091881364584
2023-05-09 18:14:01,383 :: INFO :: ----- val -----
2023-05-09 18:14:01,383 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 18:14:01,383 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 18:14:01,383 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 18:14:55,632 :: INFO :: ----- test -----
2023-05-09 18:14:55,632 :: INFO :: Precision [0.0, 5.458813253998581e-06, 8.188219880997872e-06]
2023-05-09 18:14:55,632 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 8.18821988099787e-05]
2023-05-09 18:14:55,632 :: INFO :: ndcg [0.0, 1.0558786157392369e-05, 2.8891447981011318e-05]
2023-05-09 18:17:25,555 :: INFO :: Epoch 150: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029081387910991907, MLP.norm 0.003031283849850297
2023-05-09 18:18:20,133 :: INFO :: ----- val -----
2023-05-09 18:18:20,133 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 18:18:20,133 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 18:18:20,133 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 18:19:14,385 :: INFO :: ----- test -----
2023-05-09 18:19:14,385 :: INFO :: Precision [0.0, 0.0, 8.188219880997872e-06]
2023-05-09 18:19:14,385 :: INFO :: Recall [0.0, 0.0, 8.18821988099787e-05]
2023-05-09 18:19:14,385 :: INFO :: ndcg [0.0, 0.0, 2.654899447452732e-05]
2023-05-09 18:21:43,978 :: INFO :: Epoch 155: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029097057413309813, MLP.norm 0.0030788532458245754
2023-05-09 18:22:37,011 :: INFO :: ----- val -----
2023-05-09 18:22:37,011 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 18:22:37,011 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 18:22:37,011 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 18:23:28,996 :: INFO :: ----- test -----
2023-05-09 18:23:28,996 :: INFO :: Precision [0.0, 5.458813253998581e-06, 1.0917626507997163e-05]
2023-05-09 18:23:28,996 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 0.00010917626507997162]
2023-05-09 18:23:28,996 :: INFO :: ndcg [0.0, 1.1754914516987637e-05, 3.6471320946585264e-05]
2023-05-09 18:25:52,667 :: INFO :: Epoch 160: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029114980716258287, MLP.norm 0.0033454964868724346
2023-05-09 18:26:43,917 :: INFO :: ----- val -----
2023-05-09 18:26:43,917 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 18:26:43,917 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 18:26:43,917 :: INFO :: ndcg [0.0, 0.0, 1.5764867763134417e-05]
2023-05-09 18:27:37,092 :: INFO :: ----- test -----
2023-05-09 18:27:37,092 :: INFO :: Precision [0.0, 0.0, 5.458813253998581e-06]
2023-05-09 18:27:37,092 :: INFO :: Recall [0.0, 0.0, 5.458813253998581e-05]
2023-05-09 18:27:37,092 :: INFO :: ndcg [0.0, 0.0, 1.6826651903753206e-05]
2023-05-09 18:30:03,089 :: INFO :: Epoch 165: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.00291279680095613, MLP.norm 0.0030129028018563986
2023-05-09 18:30:54,792 :: INFO :: ----- val -----
2023-05-09 18:30:54,792 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 18:30:54,792 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 18:30:54,792 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 18:31:47,479 :: INFO :: ----- test -----
2023-05-09 18:31:47,479 :: INFO :: Precision [0.0, 1.6376439761995743e-05, 1.910584638899503e-05]
2023-05-09 18:31:47,479 :: INFO :: Recall [0.0, 8.18821988099787e-05, 0.00017741143075495388]
2023-05-09 18:31:47,479 :: INFO :: ndcg [0.0, 4.8088310146375756e-05, 8.030048449988136e-05]
2023-05-09 18:34:13,166 :: INFO :: Epoch 170: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.00291051366366446, MLP.norm 0.0031853222753852606
2023-05-09 18:35:05,776 :: INFO :: ----- val -----
2023-05-09 18:35:05,776 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 18:35:05,776 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 18:35:05,776 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 18:35:59,434 :: INFO :: ----- test -----
2023-05-09 18:35:59,434 :: INFO :: Precision [0.0, 5.458813253998581e-06, 1.0917626507997163e-05]
2023-05-09 18:35:59,434 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 0.00010917626507997162]
2023-05-09 18:35:59,434 :: INFO :: ndcg [0.0, 1.1754914516987637e-05, 3.790992238957852e-05]
2023-05-09 18:38:23,090 :: INFO :: Epoch 175: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.002915597753599286, MLP.norm 0.003172821132466197
2023-05-09 18:39:16,559 :: INFO :: ----- val -----
2023-05-09 18:39:16,559 :: INFO :: Precision [0.0, 0.0, 8.851515822084533e-06]
2023-05-09 18:39:16,559 :: INFO :: Recall [0.0, 0.0, 8.851515822084532e-05]
2023-05-09 18:39:16,559 :: INFO :: ndcg [0.0, 0.0, 2.6755021159708636e-05]
2023-05-09 18:40:10,512 :: INFO :: ----- test -----
2023-05-09 18:40:10,512 :: INFO :: Precision [0.0, 5.458813253998581e-06, 1.3647033134996452e-05]
2023-05-09 18:40:10,512 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 0.00013647033134996453]
2023-05-09 18:40:10,512 :: INFO :: ndcg [0.0, 1.1754914516987637e-05, 4.74019310815126e-05]
2023-05-09 18:42:35,231 :: INFO :: Epoch 180: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029054644983261824, MLP.norm 0.0031914091669023037
2023-05-09 18:43:27,746 :: INFO :: ----- val -----
2023-05-09 18:43:27,746 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 18:43:27,746 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 18:43:27,746 :: INFO :: ndcg [0.0, 0.0, 1.2793309418804509e-05]
2023-05-09 18:44:19,746 :: INFO :: ----- test -----
2023-05-09 18:44:19,746 :: INFO :: Precision [0.0, 5.458813253998581e-06, 2.1835253015994322e-05]
2023-05-09 18:44:19,746 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 0.00020470549702494677]
2023-05-09 18:44:19,746 :: INFO :: ndcg [0.0, 1.1754914516987637e-05, 7.253195872644059e-05]
2023-05-09 18:46:44,152 :: INFO :: Epoch 185: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.002907408867031336, MLP.norm 0.0032208531629294157
2023-05-09 18:47:36,811 :: INFO :: ----- val -----
2023-05-09 18:47:36,811 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 18:47:36,811 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 18:47:36,811 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 18:48:29,014 :: INFO :: ----- test -----
2023-05-09 18:48:29,014 :: INFO :: Precision [0.0, 5.458813253998581e-06, 8.188219880997872e-06]
2023-05-09 18:48:29,014 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 6.823516567498226e-05]
2023-05-09 18:48:29,014 :: INFO :: ndcg [0.0, 1.0558786157392369e-05, 2.633829520908121e-05]
2023-05-09 18:50:53,048 :: INFO :: Epoch 190: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.002918819896876812, MLP.norm 0.0032479562796652317
2023-05-09 18:51:45,891 :: INFO :: ----- val -----
2023-05-09 18:51:45,891 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 18:51:45,891 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 18:51:45,891 :: INFO :: ndcg [0.0, 0.0, 1.5764867763134417e-05]
2023-05-09 18:52:38,391 :: INFO :: ----- test -----
2023-05-09 18:52:38,391 :: INFO :: Precision [0.0, 5.458813253998581e-06, 5.458813253998581e-06]
2023-05-09 18:52:38,391 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 5.458813253998581e-05]
2023-05-09 18:52:38,391 :: INFO :: ndcg [0.0, 1.0558786157392369e-05, 1.9169105410237195e-05]
2023-05-09 18:55:00,892 :: INFO :: Epoch 195: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029198843985795975, MLP.norm 0.003172836499288678
2023-05-09 18:55:53,064 :: INFO :: ----- val -----
2023-05-09 18:55:53,064 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 18:55:53,064 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 18:55:53,064 :: INFO :: ndcg [0.0, 0.0, 1.3322858847708838e-05]
2023-05-09 18:56:45,345 :: INFO :: ----- test -----
2023-05-09 18:56:45,345 :: INFO :: Precision [0.0, 1.0917626507997163e-05, 1.3647033134996452e-05]
2023-05-09 18:56:45,345 :: INFO :: Recall [0.0, 5.458813253998581e-05, 0.00013647033134996453]
2023-05-09 18:56:45,345 :: INFO :: ndcg [0.0, 2.8975553022677294e-05, 5.447740464514025e-05]
2023-05-09 18:59:08,377 :: INFO :: Epoch 200: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.002917190082371235, MLP.norm 0.003140825778245926
2023-05-09 18:59:59,189 :: INFO :: ----- val -----
2023-05-09 18:59:59,189 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 18:59:59,189 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 18:59:59,189 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 19:00:50,455 :: INFO :: ----- test -----
2023-05-09 19:00:50,455 :: INFO :: Precision [0.0, 0.0, 5.458813253998581e-06]
2023-05-09 19:00:50,455 :: INFO :: Recall [0.0, 0.0, 5.458813253998581e-05]
2023-05-09 19:00:50,455 :: INFO :: ndcg [0.0, 0.0, 1.6987776615842055e-05]
2023-05-09 19:03:12,345 :: INFO :: Epoch 205: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.002912212396040559, MLP.norm 0.0030464334413409233
2023-05-09 19:04:04,283 :: INFO :: ----- val -----
2023-05-09 19:04:04,283 :: INFO :: Precision [0.0, 0.0, 8.851515822084533e-06]
2023-05-09 19:04:04,283 :: INFO :: Recall [0.0, 0.0, 8.851515822084532e-05]
2023-05-09 19:04:04,283 :: INFO :: ndcg [0.0, 0.0, 2.611616826651335e-05]
2023-05-09 19:04:57,142 :: INFO :: ----- test -----
2023-05-09 19:04:57,142 :: INFO :: Precision [0.0, 5.458813253998581e-06, 8.188219880997872e-06]
2023-05-09 19:04:57,142 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 8.18821988099787e-05]
2023-05-09 19:04:57,142 :: INFO :: ndcg [0.0, 1.3647033134996452e-05, 3.158570835667895e-05]
2023-05-09 19:07:21,548 :: INFO :: Epoch 210: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.002917748410254717, MLP.norm 0.0030469889752566814
2023-05-09 19:08:13,423 :: INFO :: ----- val -----
2023-05-09 19:08:13,423 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 19:08:13,423 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 19:08:13,423 :: INFO :: ndcg [0.0, 0.0, 1.3322858847708838e-05]
2023-05-09 19:09:07,252 :: INFO :: ----- test -----
2023-05-09 19:09:07,252 :: INFO :: Precision [0.0, 1.6376439761995743e-05, 1.0917626507997163e-05]
2023-05-09 19:09:07,252 :: INFO :: Recall [0.0, 8.18821988099787e-05, 0.00010917626507997162]
2023-05-09 19:09:07,252 :: INFO :: ndcg [0.0, 4.262258615767374e-05, 5.045281011043905e-05]
2023-05-09 19:11:34,910 :: INFO :: Epoch 215: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.002911682240664959, MLP.norm 0.003165618749335408
2023-05-09 19:12:26,725 :: INFO :: ----- val -----
2023-05-09 19:12:26,725 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 19:12:26,725 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 19:12:26,725 :: INFO :: ndcg [0.0, 0.0, 1.3322858847708838e-05]
2023-05-09 19:13:20,443 :: INFO :: ----- test -----
2023-05-09 19:13:20,443 :: INFO :: Precision [0.0, 1.6376439761995743e-05, 1.3647033134996452e-05]
2023-05-09 19:13:20,443 :: INFO :: Recall [0.0, 8.18821988099787e-05, 0.00013647033134996453]
2023-05-09 19:13:20,443 :: INFO :: ndcg [0.0, 3.953433918006966e-05, 5.7473014401752154e-05]
2023-05-09 19:15:44,646 :: INFO :: Epoch 220: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029127190355211496, MLP.norm 0.0032292259857058525
2023-05-09 19:16:35,959 :: INFO :: ----- val -----
2023-05-09 19:16:35,959 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 19:16:35,959 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 19:16:35,959 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 19:17:26,256 :: INFO :: ----- test -----
2023-05-09 19:17:26,256 :: INFO :: Precision [0.0, 0.0, 2.7294066269992907e-06]
2023-05-09 19:17:26,256 :: INFO :: Recall [0.0, 0.0, 2.7294066269992904e-05]
2023-05-09 19:17:26,256 :: INFO :: ndcg [0.0, 0.0, 9.098022089997634e-06]
2023-05-09 19:19:45,037 :: INFO :: Epoch 225: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.002912531141191721, MLP.norm 0.002979489741846919
2023-05-09 19:20:34,990 :: INFO :: ----- val -----
2023-05-09 19:20:34,990 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 19:20:34,990 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 19:20:34,990 :: INFO :: ndcg [0.0, 0.0, 1.3322858847708838e-05]
2023-05-09 19:21:26,334 :: INFO :: ----- test -----
2023-05-09 19:21:26,334 :: INFO :: Precision [0.0, 5.458813253998581e-06, 1.0917626507997163e-05]
2023-05-09 19:21:26,334 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 0.00010917626507997162]
2023-05-09 19:21:26,334 :: INFO :: ndcg [0.0, 1.3647033134996452e-05, 3.924512900368333e-05]
2023-05-09 19:23:45,320 :: INFO :: Epoch 230: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029126936569809914, MLP.norm 0.003260463010519743
2023-05-09 19:24:35,664 :: INFO :: ----- val -----
2023-05-09 19:24:35,664 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 19:24:35,664 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 19:24:35,664 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 19:25:27,414 :: INFO :: ----- test -----
2023-05-09 19:25:27,429 :: INFO :: Precision [0.0, 1.0917626507997163e-05, 1.0917626507997163e-05]
2023-05-09 19:25:27,429 :: INFO :: Recall [0.0, 5.458813253998581e-05, 0.00010917626507997162]
2023-05-09 19:25:27,429 :: INFO :: ndcg [0.0, 2.231370067438001e-05, 4.2401863472384085e-05]
2023-05-09 19:27:47,586 :: INFO :: Epoch 235: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.002905043540522456, MLP.norm 0.003058401169255376
2023-05-09 19:28:39,257 :: INFO :: ----- val -----
2023-05-09 19:28:39,257 :: INFO :: Precision [0.0, 0.0, 1.7703031644169066e-05]
2023-05-09 19:28:39,257 :: INFO :: Recall [0.0, 0.0, 0.00017703031644169064]
2023-05-09 19:28:39,257 :: INFO :: ndcg [0.0, 0.0, 6.008791270820777e-05]
2023-05-09 19:29:30,398 :: INFO :: ----- test -----
2023-05-09 19:29:30,398 :: INFO :: Precision [0.0, 5.458813253998581e-06, 1.910584638899503e-05]
2023-05-09 19:29:30,398 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 0.00019105846388995032]
2023-05-09 19:29:30,398 :: INFO :: ndcg [0.0, 1.0558786157392369e-05, 6.247301461075898e-05]
2023-05-09 19:31:50,132 :: INFO :: Epoch 240: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029147076420485973, MLP.norm 0.003178003476932645
2023-05-09 19:32:40,119 :: INFO :: ----- val -----
2023-05-09 19:32:40,119 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 19:32:40,119 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 19:32:40,119 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 19:33:30,650 :: INFO :: ----- test -----
2023-05-09 19:33:30,650 :: INFO :: Precision [0.0, 1.6376439761995743e-05, 1.0917626507997163e-05]
2023-05-09 19:33:30,650 :: INFO :: Recall [0.0, 8.18821988099787e-05, 0.00010917626507997162]
2023-05-09 19:33:30,650 :: INFO :: ndcg [0.0, 4.8088310146375756e-05, 5.630464279728414e-05]
2023-05-09 19:35:49,339 :: INFO :: Epoch 245: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.002908914815634489, MLP.norm 0.003065068507567048
2023-05-09 19:36:40,761 :: INFO :: ----- val -----
2023-05-09 19:36:40,761 :: INFO :: Precision [0.0, 8.851515822084533e-06, 1.32772737331268e-05]
2023-05-09 19:36:40,761 :: INFO :: Recall [0.0, 4.425757911042266e-05, 0.00013277273733126798]
2023-05-09 19:36:40,761 :: INFO :: ndcg [0.0, 1.7121168720271814e-05, 4.820404918144776e-05]
2023-05-09 19:37:33,917 :: INFO :: ----- test -----
2023-05-09 19:37:33,917 :: INFO :: Precision [0.0, 5.458813253998581e-06, 8.188219880997872e-06]
2023-05-09 19:37:33,917 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 8.18821988099787e-05]
2023-05-09 19:37:33,917 :: INFO :: ndcg [0.0, 1.3647033134996452e-05, 2.9463255859830094e-05]
2023-05-09 19:39:56,277 :: INFO :: Epoch 250: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029191658832132816, MLP.norm 0.003083261428400874
2023-05-09 19:40:48,214 :: INFO :: ----- val -----
2023-05-09 19:40:48,214 :: INFO :: Precision [0.0, 0.0, 8.851515822084533e-06]
2023-05-09 19:40:48,214 :: INFO :: Recall [0.0, 0.0, 8.851515822084532e-05]
2023-05-09 19:40:48,214 :: INFO :: ndcg [0.0, 0.0, 2.5586618837609017e-05]
2023-05-09 19:41:40,042 :: INFO :: ----- test -----
2023-05-09 19:41:40,042 :: INFO :: Precision [0.0, 5.458813253998581e-06, 5.458813253998581e-06]
2023-05-09 19:41:40,042 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 5.458813253998581e-05]
2023-05-09 19:41:40,042 :: INFO :: ndcg [0.0, 1.3647033134996452e-05, 2.186336578590483e-05]
2023-05-09 19:44:03,888 :: INFO :: Epoch 255: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029122140258550644, MLP.norm 0.0030063698068261147
2023-05-09 19:44:55,842 :: INFO :: ----- val -----
2023-05-09 19:44:55,842 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 19:44:55,842 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 19:44:55,842 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 19:45:49,294 :: INFO :: ----- test -----
2023-05-09 19:45:49,294 :: INFO :: Precision [0.0, 0.0, 8.188219880997872e-06]
2023-05-09 19:45:49,294 :: INFO :: Recall [0.0, 0.0, 8.18821988099787e-05]
2023-05-09 19:45:49,294 :: INFO :: ndcg [0.0, 0.0, 2.7036697311680132e-05]
2023-05-09 19:48:14,985 :: INFO :: Epoch 260: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.002911278745159507, MLP.norm 0.0031215001363307238
2023-05-09 19:49:08,125 :: INFO :: ----- val -----
2023-05-09 19:49:08,125 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 19:49:08,125 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 19:49:08,125 :: INFO :: ndcg [0.0, 0.0, 1.3961711740904128e-05]
2023-05-09 19:50:01,828 :: INFO :: ----- test -----
2023-05-09 19:50:01,828 :: INFO :: Precision [0.0, 5.458813253998581e-06, 1.0917626507997163e-05]
2023-05-09 19:50:01,828 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 0.00010917626507997162]
2023-05-09 19:50:01,828 :: INFO :: ndcg [0.0, 1.1754914516987637e-05, 3.9615916210728074e-05]
2023-05-09 19:52:25,547 :: INFO :: Epoch 265: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029153800569474697, MLP.norm 0.0031248596496880054
2023-05-09 19:53:17,094 :: INFO :: ----- val -----
2023-05-09 19:53:17,094 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 19:53:17,094 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 19:53:17,094 :: INFO :: ndcg [0.0, 0.0, 1.2793309418804509e-05]
2023-05-09 19:54:09,438 :: INFO :: ----- test -----
2023-05-09 19:54:09,438 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 19:54:09,438 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 19:54:09,438 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 19:56:30,875 :: INFO :: Epoch 270: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.002908773487433791, MLP.norm 0.003327795770019293
2023-05-09 19:57:22,891 :: INFO :: ----- val -----
2023-05-09 19:57:22,891 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 19:57:22,891 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 19:57:22,891 :: INFO :: ndcg [0.0, 0.0, 1.2793309418804509e-05]
2023-05-09 19:58:15,359 :: INFO :: ----- test -----
2023-05-09 19:58:15,359 :: INFO :: Precision [0.0, 0.0, 5.458813253998581e-06]
2023-05-09 19:58:15,359 :: INFO :: Recall [0.0, 0.0, 5.458813253998581e-05]
2023-05-09 19:58:15,359 :: INFO :: ndcg [0.0, 0.0, 1.7938675221682498e-05]
2023-05-09 20:00:36,485 :: INFO :: Epoch 275: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029188422486186028, MLP.norm 0.003123202361166477
2023-05-09 20:01:28,359 :: INFO :: ----- val -----
2023-05-09 20:01:28,359 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 20:01:28,359 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 20:01:28,359 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 20:02:19,813 :: INFO :: ----- test -----
2023-05-09 20:02:19,813 :: INFO :: Precision [0.0, 5.458813253998581e-06, 1.0917626507997163e-05]
2023-05-09 20:02:19,813 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 0.00010917626507997162]
2023-05-09 20:02:19,813 :: INFO :: ndcg [0.0, 1.0558786157392369e-05, 3.7583344264514556e-05]
2023-05-09 20:04:40,971 :: INFO :: Epoch 280: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.002912033349275589, MLP.norm 0.0031031658872962
2023-05-09 20:05:32,174 :: INFO :: ----- val -----
2023-05-09 20:05:32,174 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 20:05:32,174 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 20:05:32,174 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 20:06:23,284 :: INFO :: ----- test -----
2023-05-09 20:06:23,284 :: INFO :: Precision [0.0, 1.0917626507997163e-05, 8.188219880997872e-06]
2023-05-09 20:06:23,284 :: INFO :: Recall [0.0, 5.458813253998581e-05, 8.18821988099787e-05]
2023-05-09 20:06:23,284 :: INFO :: ndcg [0.0, 2.420581929238882e-05, 3.392816186316294e-05]
2023-05-09 20:08:45,769 :: INFO :: Epoch 285: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0028964236844331026, MLP.norm 0.003234168514609337
2023-05-09 20:09:36,753 :: INFO :: ----- val -----
2023-05-09 20:09:36,753 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 20:09:36,753 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 20:09:36,753 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 20:10:28,738 :: INFO :: ----- test -----
2023-05-09 20:10:28,738 :: INFO :: Precision [0.0, 5.458813253998581e-06, 8.188219880997872e-06]
2023-05-09 20:10:28,738 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 8.18821988099787e-05]
2023-05-09 20:10:28,738 :: INFO :: ndcg [0.0, 1.1754914516987637e-05, 3.0087576340606586e-05]
2023-05-09 20:12:51,708 :: INFO :: Epoch 290: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029167572502046824, MLP.norm 0.003199964761734009
2023-05-09 20:13:45,615 :: INFO :: ----- val -----
2023-05-09 20:13:45,615 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 20:13:45,615 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 20:13:45,615 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 20:14:38,599 :: INFO :: ----- test -----
2023-05-09 20:14:38,615 :: INFO :: Precision [0.0, 0.0, 5.458813253998581e-06]
2023-05-09 20:14:38,615 :: INFO :: Recall [0.0, 0.0, 5.458813253998581e-05]
2023-05-09 20:14:38,615 :: INFO :: ndcg [0.0, 0.0, 1.6826651903753206e-05]
2023-05-09 20:17:03,521 :: INFO :: Epoch 295: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.002912089228630066, MLP.norm 0.003151766723021865
2023-05-09 20:17:55,537 :: INFO :: ----- val -----
2023-05-09 20:17:55,537 :: INFO :: Precision [0.0, 0.0, 8.851515822084533e-06]
2023-05-09 20:17:55,537 :: INFO :: Recall [0.0, 0.0, 8.851515822084532e-05]
2023-05-09 20:17:55,537 :: INFO :: ndcg [0.0, 0.0, 2.972657950403855e-05]
2023-05-09 20:18:47,802 :: INFO :: ----- test -----
2023-05-09 20:18:47,802 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 20:18:47,802 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 20:18:47,802 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 20:21:14,318 :: INFO :: Epoch 300: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.00290785264223814, MLP.norm 0.0031724954023957253
2023-05-09 20:22:07,459 :: INFO :: ----- val -----
2023-05-09 20:22:07,459 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 20:22:07,459 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 20:22:07,459 :: INFO :: ndcg [0.0, 0.0, 1.4752526370140887e-05]
2023-05-09 20:23:00,271 :: INFO :: ----- test -----
2023-05-09 20:23:00,271 :: INFO :: Precision [0.0, 1.0917626507997163e-05, 1.637643976199574e-05]
2023-05-09 20:23:00,271 :: INFO :: Recall [0.0, 5.458813253998581e-05, 0.0001637643976199574]
2023-05-09 20:23:00,271 :: INFO :: ndcg [0.0, 2.8975553022677294e-05, 6.0712163743588036e-05]
2023-05-09 20:25:26,287 :: INFO :: Epoch 305: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029178359545767307, MLP.norm 0.0031109419651329517
2023-05-09 20:26:17,818 :: INFO :: ----- val -----
2023-05-09 20:26:17,818 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 20:26:17,818 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 20:26:17,818 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 20:27:10,583 :: INFO :: ----- test -----
2023-05-09 20:27:10,583 :: INFO :: Precision [0.0, 5.458813253998581e-06, 1.0917626507997163e-05]
2023-05-09 20:27:10,583 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 0.00010917626507997162]
2023-05-09 20:27:10,583 :: INFO :: ndcg [0.0, 1.3647033134996452e-05, 3.957170712874729e-05]
2023-05-09 20:29:35,756 :: INFO :: Epoch 310: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029048931319266558, MLP.norm 0.003188258735463023
2023-05-09 20:30:27,271 :: INFO :: ----- val -----
2023-05-09 20:30:27,271 :: INFO :: Precision [0.0, 0.0, 8.851515822084533e-06]
2023-05-09 20:30:27,271 :: INFO :: Recall [0.0, 0.0, 8.851515822084532e-05]
2023-05-09 20:30:27,271 :: INFO :: ndcg [0.0, 0.0, 2.8075385217849723e-05]
2023-05-09 20:31:19,158 :: INFO :: ----- test -----
2023-05-09 20:31:19,158 :: INFO :: Precision [0.0, 1.0917626507997163e-05, 1.637643976199574e-05]
2023-05-09 20:31:19,158 :: INFO :: Recall [0.0, 5.458813253998581e-05, 0.0001637643976199574]
2023-05-09 20:31:19,158 :: INFO :: ndcg [0.0, 2.5401947651984092e-05, 5.96103627735158e-05]
2023-05-09 20:33:42,880 :: INFO :: Epoch 315: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.002920356346294284, MLP.norm 0.003150159027427435
2023-05-09 20:34:34,098 :: INFO :: ----- val -----
2023-05-09 20:34:34,098 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 20:34:34,098 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 20:34:34,098 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 20:35:25,911 :: INFO :: ----- test -----
2023-05-09 20:35:25,911 :: INFO :: Precision [2.7294066269992904e-05, 1.6376439761995743e-05, 1.3647033134996452e-05]
2023-05-09 20:35:25,911 :: INFO :: Recall [2.7294066269992904e-05, 8.18821988099787e-05, 0.00013647033134996453]
2023-05-09 20:35:25,911 :: INFO :: ndcg [2.7294066269992904e-05, 5.269601392197699e-05, 6.913655712758712e-05]
2023-05-09 20:37:52,973 :: INFO :: Epoch 320: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.00291041424497962, MLP.norm 0.0030407949816435575
2023-05-09 20:38:45,583 :: INFO :: ----- val -----
2023-05-09 20:38:45,583 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 20:38:45,583 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 20:38:45,583 :: INFO :: ndcg [0.0, 0.0, 1.3961711740904128e-05]
2023-05-09 20:39:38,442 :: INFO :: ----- test -----
2023-05-09 20:39:38,442 :: INFO :: Precision [0.0, 0.0, 1.3647033134996452e-05]
2023-05-09 20:39:38,442 :: INFO :: Recall [0.0, 0.0, 0.00013647033134996453]
2023-05-09 20:39:38,442 :: INFO :: ndcg [0.0, 0.0, 4.562672809361184e-05]
2023-05-09 20:42:04,301 :: INFO :: Epoch 325: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.002904237248003483, MLP.norm 0.0030400606337934732
2023-05-09 20:42:56,723 :: INFO :: ----- val -----
2023-05-09 20:42:56,723 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 20:42:56,723 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 20:42:56,723 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 20:43:49,301 :: INFO :: ----- test -----
2023-05-09 20:43:49,301 :: INFO :: Precision [0.0, 5.458813253998581e-06, 8.188219880997872e-06]
2023-05-09 20:43:49,301 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 8.18821988099787e-05]
2023-05-09 20:43:49,301 :: INFO :: ndcg [0.0, 1.7220638505689654e-05, 3.404729040944286e-05]
2023-05-09 20:46:14,897 :: INFO :: Epoch 330: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029109627939760685, MLP.norm 0.0031106777023524046
2023-05-09 20:47:08,476 :: INFO :: ----- val -----
2023-05-09 20:47:08,491 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 20:47:08,491 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 20:47:08,491 :: INFO :: ndcg [0.0, 0.0, 1.3322858847708838e-05]
2023-05-09 20:47:59,038 :: INFO :: ----- test -----
2023-05-09 20:47:59,038 :: INFO :: Precision [0.0, 0.0, 5.458813253998581e-06]
2023-05-09 20:47:59,038 :: INFO :: Recall [0.0, 0.0, 5.458813253998581e-05]
2023-05-09 20:47:59,038 :: INFO :: ndcg [0.0, 0.0, 1.8820364660771752e-05]
2023-05-09 20:50:22,212 :: INFO :: Epoch 335: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029164066072553396, MLP.norm 0.0031636457424610853
2023-05-09 20:51:16,572 :: INFO :: ----- val -----
2023-05-09 20:51:16,572 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 20:51:16,572 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 20:51:16,572 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 20:52:09,588 :: INFO :: ----- test -----
2023-05-09 20:52:09,588 :: INFO :: Precision [0.0, 5.458813253998581e-06, 1.3647033134996452e-05]
2023-05-09 20:52:09,588 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 0.00013647033134996453]
2023-05-09 20:52:09,588 :: INFO :: ndcg [0.0, 1.0558786157392369e-05, 4.683012320269381e-05]
2023-05-09 20:54:38,978 :: INFO :: Epoch 340: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029118226375430822, MLP.norm 0.003045374061912298
2023-05-09 20:55:34,134 :: INFO :: ----- val -----
2023-05-09 20:55:34,134 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 20:55:34,134 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 20:55:34,134 :: INFO :: ndcg [0.0, 0.0, 1.3322858847708838e-05]
2023-05-09 20:56:28,088 :: INFO :: ----- test -----
2023-05-09 20:56:28,088 :: INFO :: Precision [0.0, 2.1835253015994326e-05, 1.0917626507997163e-05]
2023-05-09 20:56:28,088 :: INFO :: Recall [0.0, 0.00010917626507997162, 0.00010917626507997162]
2023-05-09 20:56:28,088 :: INFO :: ndcg [0.0, 5.248538205665257e-05, 5.62696192926702e-05]
2023-05-09 20:58:53,838 :: INFO :: Epoch 345: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029137178789824247, MLP.norm 0.0030087188351899385
2023-05-09 20:59:46,462 :: INFO :: ----- val -----
2023-05-09 20:59:46,462 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 20:59:46,462 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 20:59:46,462 :: INFO :: ndcg [0.0, 0.0, 1.2793309418804509e-05]
2023-05-09 21:00:39,197 :: INFO :: ----- test -----
2023-05-09 21:00:39,197 :: INFO :: Precision [0.0, 0.0, 1.0917626507997163e-05]
2023-05-09 21:00:39,197 :: INFO :: Recall [0.0, 0.0, 0.00010917626507997162]
2023-05-09 21:00:39,197 :: INFO :: ndcg [0.0, 0.0, 3.4628709481812026e-05]
2023-05-09 21:03:00,822 :: INFO :: Epoch 350: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029053599573671818, MLP.norm 0.003061627736315131
2023-05-09 21:03:53,744 :: INFO :: ----- val -----
2023-05-09 21:03:53,744 :: INFO :: Precision [0.0, 8.851515822084533e-06, 4.4257579110422665e-06]
2023-05-09 21:03:53,744 :: INFO :: Recall [0.0, 4.425757911042266e-05, 4.425757911042266e-05]
2023-05-09 21:03:53,744 :: INFO :: ndcg [0.0, 1.7121168720271814e-05, 1.7121168720271814e-05]
2023-05-09 21:04:46,087 :: INFO :: ----- test -----
2023-05-09 21:04:46,087 :: INFO :: Precision [0.0, 5.458813253998581e-06, 5.458813253998581e-06]
2023-05-09 21:04:46,087 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 5.458813253998581e-05]
2023-05-09 21:04:46,087 :: INFO :: ndcg [0.0, 1.0558786157392369e-05, 1.877511880830075e-05]
2023-05-09 21:07:07,543 :: INFO :: Epoch 355: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029179996345192194, MLP.norm 0.003176076104864478
2023-05-09 21:08:00,387 :: INFO :: ----- val -----
2023-05-09 21:08:00,387 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 21:08:00,387 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 21:08:00,387 :: INFO :: ndcg [0.0, 0.0, 1.3322858847708838e-05]
2023-05-09 21:08:53,043 :: INFO :: ----- test -----
2023-05-09 21:08:53,043 :: INFO :: Precision [0.0, 5.458813253998581e-06, 1.3647033134996452e-05]
2023-05-09 21:08:53,043 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 0.00012282329821496806]
2023-05-09 21:08:53,043 :: INFO :: ndcg [0.0, 1.7220638505689654e-05, 5.022078606306815e-05]
2023-05-09 21:11:14,386 :: INFO :: Epoch 360: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029112352058291435, MLP.norm 0.0030939860735088587
2023-05-09 21:12:06,949 :: INFO :: ----- val -----
2023-05-09 21:12:06,965 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 21:12:06,965 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 21:12:06,965 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 21:12:59,199 :: INFO :: ----- test -----
2023-05-09 21:12:59,199 :: INFO :: Precision [0.0, 0.0, 5.458813253998581e-06]
2023-05-09 21:12:59,199 :: INFO :: Recall [0.0, 0.0, 5.458813253998581e-05]
2023-05-09 21:12:59,199 :: INFO :: ndcg [0.0, 0.0, 1.6500073778689248e-05]
2023-05-09 21:15:20,511 :: INFO :: Epoch 365: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029151856433600187, MLP.norm 0.0030440499540418386
2023-05-09 21:16:13,324 :: INFO :: ----- val -----
2023-05-09 21:16:13,324 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 21:16:13,324 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 21:16:13,324 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 21:17:07,139 :: INFO :: ----- test -----
2023-05-09 21:17:07,139 :: INFO :: Precision [0.0, 0.0, 2.7294066269992907e-06]
2023-05-09 21:17:07,139 :: INFO :: Recall [0.0, 0.0, 2.7294066269992904e-05]
2023-05-09 21:17:07,139 :: INFO :: ndcg [0.0, 0.0, 9.098022089997634e-06]
2023-05-09 21:35:31,503 :: INFO :: Epoch 370: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.002903013490140438, MLP.norm 0.0031122229993343353
2023-05-09 21:36:26,112 :: INFO :: ----- val -----
2023-05-09 21:36:26,112 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 21:36:26,112 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 21:36:26,112 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 21:37:22,174 :: INFO :: ----- test -----
2023-05-09 21:37:22,174 :: INFO :: Precision [0.0, 5.458813253998581e-06, 5.458813253998581e-06]
2023-05-09 21:37:22,174 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 5.458813253998581e-05]
2023-05-09 21:37:22,174 :: INFO :: ndcg [0.0, 1.0558786157392369e-05, 1.844854068323679e-05]
2023-05-09 21:39:51,018 :: INFO :: Epoch 375: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029140901751816273, MLP.norm 0.0031656590290367603
2023-05-09 21:40:45,878 :: INFO :: ----- val -----
2023-05-09 21:40:45,878 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 21:40:45,878 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 21:40:45,878 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 21:41:40,377 :: INFO :: ----- test -----
2023-05-09 21:41:40,377 :: INFO :: Precision [0.0, 1.0917626507997163e-05, 1.0917626507997163e-05]
2023-05-09 21:41:40,377 :: INFO :: Recall [0.0, 5.458813253998581e-05, 0.00010917626507997162]
2023-05-09 21:41:40,377 :: INFO :: ndcg [0.0, 2.3509829033975273e-05, 4.2284947842276025e-05]
2023-05-09 21:44:07,393 :: INFO :: Epoch 380: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029138994868844748, MLP.norm 0.003135229228064418
2023-05-09 21:45:02,034 :: INFO :: ----- val -----
2023-05-09 21:45:02,034 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 21:45:02,034 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 21:45:02,034 :: INFO :: ndcg [0.0, 0.0, 1.3961711740904128e-05]
2023-05-09 21:45:57,112 :: INFO :: ----- test -----
2023-05-09 21:45:57,112 :: INFO :: Precision [0.0, 2.1835253015994326e-05, 2.1835253015994322e-05]
2023-05-09 21:45:57,112 :: INFO :: Recall [0.0, 0.00010917626507997162, 0.00021835253015994323]
2023-05-09 21:45:57,112 :: INFO :: ndcg [0.0, 5.009312533746203e-05, 8.541356377692303e-05]
2023-05-09 21:48:24,581 :: INFO :: Epoch 385: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.002906573237851262, MLP.norm 0.003204020904377103
2023-05-09 21:49:19,550 :: INFO :: ----- val -----
2023-05-09 21:49:19,565 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 21:49:19,565 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 21:49:19,565 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 21:50:14,752 :: INFO :: ----- test -----
2023-05-09 21:50:14,752 :: INFO :: Precision [0.0, 1.0917626507997163e-05, 1.637643976199574e-05]
2023-05-09 21:50:14,752 :: INFO :: Recall [0.0, 5.458813253998581e-05, 0.0001637643976199574]
2023-05-09 21:50:14,752 :: INFO :: ndcg [0.0, 3.08676716406861e-05, 6.327768437942536e-05]
2023-05-09 21:52:44,752 :: INFO :: Epoch 390: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029145439621061087, MLP.norm 0.0032786685042083263
2023-05-09 21:53:40,096 :: INFO :: ----- val -----
2023-05-09 21:53:40,096 :: INFO :: Precision [0.0, 0.0, 8.851515822084533e-06]
2023-05-09 21:53:40,096 :: INFO :: Recall [0.0, 0.0, 8.851515822084532e-05]
2023-05-09 21:53:40,096 :: INFO :: ndcg [0.0, 0.0, 2.754583578894539e-05]
2023-05-09 21:54:38,283 :: INFO :: ----- test -----
2023-05-09 21:54:38,283 :: INFO :: Precision [0.0, 0.0, 1.3647033134996452e-05]
2023-05-09 21:54:38,283 :: INFO :: Recall [0.0, 0.0, 0.00013647033134996453]
2023-05-09 21:54:38,283 :: INFO :: ndcg [0.0, 0.0, 4.2030761170503644e-05]
2023-05-09 21:57:09,268 :: INFO :: Epoch 395: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029130366165190935, MLP.norm 0.0031545155216008425
2023-05-09 21:58:04,409 :: INFO :: ----- val -----
2023-05-09 21:58:04,409 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 21:58:04,409 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 21:58:04,409 :: INFO :: ndcg [0.0, 0.0, 1.3961711740904128e-05]
2023-05-09 21:59:00,284 :: INFO :: ----- test -----
2023-05-09 21:59:00,284 :: INFO :: Precision [0.0, 1.6376439761995743e-05, 2.1835253015994322e-05]
2023-05-09 21:59:00,284 :: INFO :: Recall [0.0, 8.18821988099787e-05, 0.00021835253015994323]
2023-05-09 21:59:00,284 :: INFO :: ndcg [0.0, 3.953433918006966e-05, 8.513403219420878e-05]
2023-05-09 22:01:32,065 :: INFO :: Epoch 400: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.00291411392390728, MLP.norm 0.003193510929122567
2023-05-09 22:02:27,971 :: INFO :: ----- val -----
2023-05-09 22:02:27,971 :: INFO :: Precision [0.0, 0.0, 4.4257579110422665e-06]
2023-05-09 22:02:27,971 :: INFO :: Recall [0.0, 0.0, 4.425757911042266e-05]
2023-05-09 22:02:27,971 :: INFO :: ndcg [0.0, 0.0, 1.3961711740904128e-05]
2023-05-09 22:03:24,065 :: INFO :: ----- test -----
2023-05-09 22:03:24,065 :: INFO :: Precision [0.0, 0.0, 5.458813253998581e-06]
2023-05-09 22:03:24,065 :: INFO :: Recall [0.0, 0.0, 5.458813253998581e-05]
2023-05-09 22:03:24,065 :: INFO :: ndcg [0.0, 0.0, 1.8196044179995267e-05]
2023-05-09 22:05:53,440 :: INFO :: Epoch 405: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029184306040406227, MLP.norm 0.0031225201673805714
2023-05-09 22:06:48,283 :: INFO :: ----- val -----
2023-05-09 22:06:48,283 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 22:06:48,283 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 22:06:48,283 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 22:07:43,612 :: INFO :: ----- test -----
2023-05-09 22:07:43,612 :: INFO :: Precision [0.0, 1.0917626507997163e-05, 1.0917626507997163e-05]
2023-05-09 22:07:43,612 :: INFO :: Recall [0.0, 5.458813253998581e-05, 0.00010917626507997162]
2023-05-09 22:07:43,612 :: INFO :: ndcg [0.0, 2.420581929238882e-05, 4.385048833522088e-05]
2023-05-09 22:10:13,440 :: INFO :: Epoch 410: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029029895085841417, MLP.norm 0.003133857622742653
2023-05-09 22:11:07,737 :: INFO :: ----- val -----
2023-05-09 22:11:07,737 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 22:11:07,737 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 22:11:07,737 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 22:12:02,283 :: INFO :: ----- test -----
2023-05-09 22:12:02,283 :: INFO :: Precision [0.0, 0.0, 5.458813253998581e-06]
2023-05-09 22:12:02,283 :: INFO :: Recall [0.0, 0.0, 5.458813253998581e-05]
2023-05-09 22:12:02,283 :: INFO :: ndcg [0.0, 0.0, 1.8820364660771752e-05]
2023-05-09 22:14:32,393 :: INFO :: Epoch 415: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.002919265301898122, MLP.norm 0.0031140842474997044
2023-05-09 22:15:26,987 :: INFO :: ----- val -----
2023-05-09 22:15:26,987 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 22:15:26,987 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 22:15:26,987 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 22:16:22,034 :: INFO :: ----- test -----
2023-05-09 22:16:22,034 :: INFO :: Precision [0.0, 1.0917626507997163e-05, 1.637643976199574e-05]
2023-05-09 22:16:22,034 :: INFO :: Recall [0.0, 5.458813253998581e-05, 0.00013647033134996453]
2023-05-09 22:16:22,034 :: INFO :: ndcg [0.0, 2.7294066269992904e-05, 5.794070013055364e-05]
2023-05-09 22:18:52,002 :: INFO :: Epoch 420: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.002917697187513113, MLP.norm 0.002858184976503253
2023-05-09 22:19:47,158 :: INFO :: ----- val -----
2023-05-09 22:19:47,158 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 22:19:47,158 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 22:19:47,158 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 22:20:43,112 :: INFO :: ----- test -----
2023-05-09 22:20:43,112 :: INFO :: Precision [0.0, 5.458813253998581e-06, 1.0917626507997163e-05]
2023-05-09 22:20:43,112 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 0.00010917626507997162]
2023-05-09 22:20:43,112 :: INFO :: ndcg [0.0, 1.0558786157392369e-05, 3.7893225824785024e-05]
2023-05-09 22:23:13,987 :: INFO :: Epoch 425: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029041504021734, MLP.norm 0.003276837058365345
2023-05-09 22:24:09,550 :: INFO :: ----- val -----
2023-05-09 22:24:09,550 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 22:24:09,550 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 22:24:09,550 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 22:25:06,081 :: INFO :: ----- test -----
2023-05-09 22:25:06,081 :: INFO :: Precision [0.0, 5.458813253998581e-06, 8.188219880997872e-06]
2023-05-09 22:25:06,081 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 8.18821988099787e-05]
2023-05-09 22:25:06,081 :: INFO :: ndcg [0.0, 1.3647033134996452e-05, 3.19796949586154e-05]
2023-05-09 22:27:33,037 :: INFO :: Epoch 430: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029075215570628643, MLP.norm 0.003064428223297
2023-05-09 22:28:26,162 :: INFO :: ----- val -----
2023-05-09 22:28:26,162 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 22:28:26,162 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 22:28:26,162 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 22:29:19,802 :: INFO :: ----- test -----
2023-05-09 22:29:19,802 :: INFO :: Precision [0.0, 0.0, 8.188219880997872e-06]
2023-05-09 22:29:19,802 :: INFO :: Recall [0.0, 0.0, 8.18821988099787e-05]
2023-05-09 22:29:19,802 :: INFO :: ndcg [0.0, 0.0, 2.4716406429597624e-05]
2023-05-09 22:31:45,834 :: INFO :: Epoch 435: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.002902653533965349, MLP.norm 0.0033099676948040724
2023-05-09 22:32:40,474 :: INFO :: ----- val -----
2023-05-09 22:32:40,474 :: INFO :: Precision [0.0, 8.851515822084533e-06, 4.4257579110422665e-06]
2023-05-09 22:32:40,474 :: INFO :: Recall [0.0, 4.425757911042266e-05, 4.425757911042266e-05]
2023-05-09 22:32:40,474 :: INFO :: ndcg [0.0, 1.7121168720271814e-05, 1.7121168720271814e-05]
2023-05-09 22:33:33,834 :: INFO :: ----- test -----
2023-05-09 22:33:33,834 :: INFO :: Precision [0.0, 1.6376439761995743e-05, 1.0917626507997163e-05]
2023-05-09 22:33:33,834 :: INFO :: Recall [0.0, 8.18821988099787e-05, 0.00010917626507997162]
2023-05-09 22:33:33,834 :: INFO :: ndcg [0.0, 3.715686216897173e-05, 4.348107620187129e-05]
2023-05-09 22:35:59,303 :: INFO :: Epoch 440: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.0029153884388506413, MLP.norm 0.0031722874846309423
2023-05-09 22:36:52,335 :: INFO :: ----- val -----
2023-05-09 22:36:52,335 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 22:36:52,335 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 22:36:52,335 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 22:37:45,335 :: INFO :: ----- test -----
2023-05-09 22:37:45,335 :: INFO :: Precision [0.0, 1.0917626507997163e-05, 8.188219880997872e-06]
2023-05-09 22:37:45,335 :: INFO :: Recall [0.0, 5.458813253998581e-05, 8.18821988099787e-05]
2023-05-09 22:37:45,335 :: INFO :: ndcg [0.0, 2.3509829033975273e-05, 3.0003471298940606e-05]
2023-05-09 22:40:07,085 :: INFO :: Epoch 445: loss tensor(0.9273, device='cuda:0', grad_fn=<AddBackward0>), U.norm 0.0, V.norm 0.00291261775419116, MLP.norm 0.0030980214942246675
2023-05-09 22:41:01,163 :: INFO :: ----- val -----
2023-05-09 22:41:01,163 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 22:41:01,163 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 22:41:01,163 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 22:41:54,866 :: INFO :: ----- test -----
2023-05-09 22:41:54,866 :: INFO :: Precision [0.0, 5.458813253998581e-06, 1.637643976199574e-05]
2023-05-09 22:41:54,866 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 0.00013647033134996453]
2023-05-09 22:41:54,866 :: INFO :: ndcg [0.0, 1.0558786157392369e-05, 5.2101844490743205e-05]
2023-05-09 22:41:54,882 :: INFO :: Epoch 445:
2023-05-09 22:42:48,835 :: INFO :: ----- val -----
2023-05-09 22:42:48,851 :: INFO :: Precision [0.0, 0.0, 0.0]
2023-05-09 22:42:48,851 :: INFO :: Recall [0.0, 0.0, 0.0]
2023-05-09 22:42:48,851 :: INFO :: ndcg [0.0, 0.0, 0.0]
2023-05-09 22:43:43,663 :: INFO :: ----- test -----
2023-05-09 22:43:43,663 :: INFO :: Precision [0.0, 5.458813253998581e-06, 1.637643976199574e-05]
2023-05-09 22:43:43,663 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 0.00013647033134996453]
2023-05-09 22:43:43,663 :: INFO :: ndcg [0.0, 1.0558786157392369e-05, 5.2101844490743205e-05]
2023-05-09 22:43:43,663 :: INFO :: final:
2023-05-09 22:43:43,663 :: INFO :: ----- test -----
2023-05-09 22:43:43,663 :: INFO :: Precision [0.0, 5.458813253998581e-06, 1.910584638899503e-05]
2023-05-09 22:43:43,663 :: INFO :: Recall [0.0, 2.7294066269992904e-05, 0.00019105846388995032]
2023-05-09 22:43:43,663 :: INFO :: ndcg [0.0, 1.0558786157392369e-05, 6.247301461075898e-05]
2023-05-09 22:43:43,663 :: INFO :: max_epoch 235:
