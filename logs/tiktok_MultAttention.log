2023-04-23 21:26:26,862 :: INFO :: log info to logs/tiktok_MultAttention.log
2023-04-23 21:26:26,863 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=128, dataset='tiktok', device='cpu', epoch=5, f_epoch=20, f_max=10, feat_dim=64, ite=5, lam=0.1, lr=0.001, model='MultAttention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=1, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=128, tolog=1, wdi=2)
2023-04-23 21:26:28,648 :: INFO :: torch.Size([76085, 384])
2023-04-23 21:27:09,784 :: INFO :: log info to logs/tiktok_MultAttention.log
2023-04-23 21:27:09,784 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=128, dataset='tiktok', device='cpu', epoch=5, f_epoch=20, f_max=10, feat_dim=64, ite=5, lam=0.1, lr=0.001, model='MultAttention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=1, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=128, tolog=1, wdi=2)
2023-04-23 21:27:11,651 :: INFO :: torch.Size([76085, 384])
2023-04-23 21:46:59,480 :: INFO :: log info to logs/tiktok_MultAttention.log
2023-04-23 21:46:59,481 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=128, dataset='tiktok', device='cpu', epoch=5, f_epoch=20, f_max=10, feat_dim=64, ite=5, lam=0.1, lr=0.001, model='MultAttention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=1, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=128, tolog=1, wdi=2)
2023-04-23 21:47:01,564 :: INFO :: torch.Size([76085, 384])
2023-04-23 22:23:30,285 :: INFO :: log info to logs/tiktok_MultAttention.log
2023-04-23 22:23:30,285 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=128, dataset='tiktok', device='cpu', epoch=5, f_epoch=20, f_max=10, feat_dim=64, ite=5, lam=0.1, lr=0.001, model='MultAttention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=1, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=128, tolog=1, wdi=2)
2023-04-23 22:23:32,286 :: INFO :: torch.Size([76085, 384])
2023-04-29 19:59:16,160 :: INFO :: log info to logs/tiktok_MultAttention.log
2023-04-29 19:59:16,163 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=512, dataset='tiktok', device='cpu', epoch=5, f_epoch=20, f_max=10, feat_dim=64, ite=5, lam=0.1, lr=0.001, model='MultAttention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=0, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=512, tolog=1, wdi=2)
2023-04-29 19:59:17,906 :: INFO :: torch.Size([76085, 384])
2023-04-29 20:01:17,811 :: INFO :: log info to logs/tiktok_MultAttention.log
2023-04-29 20:01:17,812 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=512, dataset='tiktok', device='cpu', epoch=5, f_epoch=20, f_max=10, feat_dim=64, ite=5, lam=0.1, lr=0.001, model='MultAttention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=0, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=512, tolog=1, wdi=2)
2023-04-29 20:01:19,851 :: INFO :: torch.Size([76085, 384])
2023-04-29 20:05:12,908 :: INFO :: log info to logs/tiktok_MultAttention.log
2023-04-29 20:05:12,908 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=512, dataset='tiktok', device='cpu', epoch=5, f_epoch=20, f_max=10, feat_dim=64, ite=5, lam=0.1, lr=0.001, model='MultAttention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=0, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=512, tolog=1, wdi=2)
2023-04-29 20:05:14,867 :: INFO :: torch.Size([76085, 384])
2023-04-29 20:06:32,286 :: INFO :: log info to logs/tiktok_MultAttention.log
2023-04-29 20:06:32,287 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=512, dataset='tiktok', device='cpu', epoch=5, f_epoch=20, f_max=10, feat_dim=64, ite=5, lam=0.1, lr=0.001, model='MultAttention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=0, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=512, tolog=1, wdi=2)
2023-04-29 20:06:33,875 :: INFO :: torch.Size([76085, 384])
2023-04-29 20:43:39,577 :: INFO :: log info to logs/tiktok_MultAttention.log
2023-04-29 20:43:39,578 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=512, dataset='tiktok', device='cpu', epoch=5, f_epoch=20, f_max=10, feat_dim=64, ite=5, lam=0.1, lr=0.001, model='MultAttention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=0, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=512, tolog=1, wdi=2)
2023-04-29 20:43:41,619 :: INFO :: torch.Size([76085, 384])
2023-04-29 20:44:24,191 :: INFO :: log info to logs/tiktok_MultAttention.log
2023-04-29 20:44:24,191 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=512, dataset='tiktok', device='cpu', epoch=5, f_epoch=20, f_max=10, feat_dim=64, ite=5, lam=0.1, lr=0.001, model='MultAttention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=0, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=512, tolog=1, wdi=2)
2023-04-29 20:44:25,792 :: INFO :: torch.Size([76085, 384])
2023-04-29 20:45:35,679 :: INFO :: log info to logs/tiktok_MultAttention.log
2023-04-29 20:45:35,679 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=512, dataset='tiktok', device='cpu', epoch=5, f_epoch=20, f_max=10, feat_dim=64, ite=5, lam=0.1, lr=0.001, model='MultAttention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=0, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=512, tolog=1, wdi=2)
2023-04-29 20:45:37,566 :: INFO :: torch.Size([76085, 384])
2023-04-29 20:46:21,061 :: INFO :: log info to logs/tiktok_MultAttention.log
2023-04-29 20:46:21,062 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=512, dataset='tiktok', device='cpu', epoch=5, f_epoch=20, f_max=10, feat_dim=64, ite=5, lam=0.1, lr=0.001, model='MultAttention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=0, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=512, tolog=1, wdi=2)
2023-04-29 20:46:22,644 :: INFO :: torch.Size([76085, 384])
2023-04-29 20:46:59,039 :: INFO :: log info to logs/tiktok_MultAttention.log
2023-04-29 20:46:59,039 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=512, dataset='tiktok', device='cpu', epoch=5, f_epoch=20, f_max=10, feat_dim=64, ite=5, lam=0.1, lr=0.001, model='MultAttention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=0, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=512, tolog=1, wdi=2)
2023-04-29 20:47:00,703 :: INFO :: torch.Size([76085, 384])
2023-04-29 20:47:21,831 :: INFO :: log info to logs/tiktok_MultAttention.log
2023-04-29 20:47:21,832 :: INFO :: Namespace(alpha=1.0, b_epoch=40, bsz=512, dataset='tiktok', device='cpu', epoch=5, f_epoch=20, f_max=10, feat_dim=64, ite=5, lam=0.1, lr=0.001, model='MultAttention', neg_num=50, neighbor_num=10, num_domains=10, num_epoch=500, p_ctx=[0.001, 0.1], p_emb=[0.001, 0.0001], p_embp=[0.001, 0.0001], p_proj=[0.001, 0.01], p_w=[1, 1, 1, 1], pretrained=0, regi=0.0, reuse=0, sift=0, sigma=0.01, ssz=512, tolog=1, wdi=2)
2023-04-29 20:47:23,382 :: INFO :: torch.Size([76085, 384])
